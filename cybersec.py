# -*- coding: utf-8 -*-
"""CYbersec

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1d2vMztVdMCze5VvucklHrMhc5onGxK-e
"""

# Install required dependencies
!pip install pandas numpy scikit-learn matplotlib



"""
Real-Time Monitoring Components for AI-Powered Threat Detection System

This module implements the real-time monitoring components of an AI-powered
threat detection system for financial institutions. The system is designed to
proactively detect various security threats including phishing attacks,
man-in-the-middle attacks, DoS, ransomware, insider threats, and malware.
"""

import logging
import json
import time
import threading
import queue
import numpy as np
from datetime import datetime
import ipaddress
import re
import hashlib
import base64
from typing import Dict, List, Any, Tuple, Optional, Union

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("monitoring_system.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger("monitoring_system")

class DataCollector:
    """Base class for all data collection components"""

    def __init__(self, name: str):
        """
        Initialize the data collector

        Args:
            name: Name of the data collector
        """
        self.name = name
        self.running = False
        self.data_queue = queue.Queue()
        self.processed_data = []
        self.collection_thread = None
        self.processing_thread = None
        logger.info(f"Initialized {name} collector")

    def start(self):
        """Start the data collector"""
        if not self.running:
            self.running = True

            # Start collection thread
            self.collection_thread = threading.Thread(target=self._collection_loop)
            self.collection_thread.daemon = True
            self.collection_thread.start()

            # Start processing thread
            self.processing_thread = threading.Thread(target=self._processing_loop)
            self.processing_thread.daemon = True
            self.processing_thread.start()

            logger.info(f"Started {self.name} collector")

    def stop(self):
        """Stop the data collector"""
        if self.running:
            self.running = False
            logger.info(f"Stopped {self.name} collector")

    def _collection_loop(self):
        """Main collection loop - to be implemented by subclasses"""
        raise NotImplementedError("Subclasses must implement _collection_loop method")

    def _processing_loop(self):
        """Main processing loop"""
        while self.running:
            try:
                # Get data batch from queue (with timeout to allow for clean shutdown)
                try:
                    data_batch = self.data_queue.get(timeout=1.0)
                except queue.Empty:
                    continue

                # Process the data batch
                processed_batch = self._process_data(data_batch)

                # Store processed data
                if processed_batch:
                    self.processed_data.extend(processed_batch)

                    # Limit stored data size
                    max_stored = 1000
                    if len(self.processed_data) > max_stored:
                        self.processed_data = self.processed_data[-max_stored:]

                # Mark as done
                self.data_queue.task_done()

            except Exception as e:
                logger.error(f"Error in {self.name} processing loop: {str(e)}")
                time.sleep(1)  # Wait before retrying

    def _process_data(self, data_batch: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Process a batch of data - to be implemented by subclasses"""
        raise NotImplementedError("Subclasses must implement _process_data method")

    def get_recent_data(self, count: int = 10) -> List[Dict[str, Any]]:
        """Get the most recent processed data"""
        return self.processed_data[-count:] if self.processed_data else []

class NetworkTrafficCollector(DataCollector):
    """Collects and processes network traffic data"""

    def __init__(self):
        super().__init__("NetworkTraffic")
        self.collection_interval = 5  # seconds

    def _collection_loop(self):
        """Collect network traffic data"""
        while self.running:
            try:
                # In a real implementation, this would interface with network monitoring tools
                # For simulation, we'll generate synthetic data
                data_batch = self._generate_synthetic_data()

                # Add to processing queue
                self.data_queue.put(data_batch)

                # Wait for next collection interval
                time.sleep(self.collection_interval)

            except Exception as e:
                logger.error(f"Error collecting network traffic data: {str(e)}")
                time.sleep(self.collection_interval)

    def _generate_synthetic_data(self) -> List[Dict[str, Any]]:
        """Generate synthetic network traffic data for simulation"""
        # Number of records to generate
        num_records = np.random.randint(5, 15)

        data_batch = []
        for _ in range(num_records):
            # Generate random IP addresses
            src_ip = f"192.168.{np.random.randint(1, 255)}.{np.random.randint(1, 255)}"
            dst_ip = f"10.0.{np.random.randint(1, 255)}.{np.random.randint(1, 255)}"

            # Generate random ports
            src_port = np.random.randint(1024, 65535)
            dst_port = np.random.choice([80, 443, 22, 25, 53, 3306, 5432])

            # Generate protocol
            protocol = np.random.choice(["TCP", "UDP", "ICMP", "HTTP", "HTTPS", "DNS"])

            # Generate traffic volume
            bytes_sent = np.random.randint(100, 10000)
            bytes_received = np.random.randint(100, 10000)

            # Generate timestamp
            timestamp = datetime.now().isoformat()

            # Create record
            record = {
                "timestamp": timestamp,
                "src_ip": src_ip,
                "dst_ip": dst_ip,
                "src_port": src_port,
                "dst_port": dst_port,
                "protocol": protocol,
                "bytes_sent": bytes_sent,
                "bytes_received": bytes_received,
                "duration": np.random.uniform(0.1, 2.0),
                "flags": np.random.choice(["S", "SA", "A", "F", "FA", "R", "P"]),
                "packets": np.random.randint(1, 100)
            }

            data_batch.append(record)

        return data_batch

    def _process_data(self, data_batch: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Process network traffic data"""
        processed_batch = []

        for record in data_batch:
            # Enrich data with additional information
            enriched_record = record.copy()

            # Add source IP type
            try:
                ip = ipaddress.ip_address(record["src_ip"])
                enriched_record["src_ip_type"] = "private" if ip.is_private else "public"
            except:
                enriched_record["src_ip_type"] = "unknown"

            # Add destination IP type
            try:
                ip = ipaddress.ip_address(record["dst_ip"])
                enriched_record["dst_ip_type"] = "private" if ip.is_private else "public"
            except:
                enriched_record["dst_ip_type"] = "unknown"

            # Add service type based on port
            dst_port = record["dst_port"]
            if dst_port == 80:
                enriched_record["service"] = "HTTP"
            elif dst_port == 443:
                enriched_record["service"] = "HTTPS"
            elif dst_port == 22:
                enriched_record["service"] = "SSH"
            elif dst_port == 25:
                enriched_record["service"] = "SMTP"
            elif dst_port == 53:
                enriched_record["service"] = "DNS"
            elif dst_port == 3306:
                enriched_record["service"] = "MySQL"
            elif dst_port == 5432:
                enriched_record["service"] = "PostgreSQL"
            else:
                enriched_record["service"] = "Other"

            # Add traffic direction
            if enriched_record["bytes_sent"] > enriched_record["bytes_received"]:
                enriched_record["direction"] = "outbound"
            else:
                enriched_record["direction"] = "inbound"

            # Add data type
            enriched_record["data_type"] = "network"

            processed_batch.append(enriched_record)

        return processed_batch

class UserBehaviorMonitor(DataCollector):
    """Monitors and analyzes user behavior patterns"""

    def __init__(self):
        super().__init__("UserBehavior")
        self.collection_interval = 10  # seconds
        self.user_profiles = {}  # user_id -> profile data

    def _collection_loop(self):
        """Collect user behavior data"""
        while self.running:
            try:
                # In a real implementation, this would interface with user activity monitoring tools
                # For simulation, we'll generate synthetic data
                data_batch = self._generate_synthetic_data()

                # Add to processing queue
                self.data_queue.put(data_batch)

                # Wait for next collection interval
                time.sleep(self.collection_interval)

            except Exception as e:
                logger.error(f"Error collecting user behavior data: {str(e)}")
                time.sleep(self.collection_interval)

    def _generate_synthetic_data(self) -> List[Dict[str, Any]]:
        """Generate synthetic user behavior data for simulation"""
        # Number of records to generate
        num_records = np.random.randint(3, 10)

        # Possible user IDs
        user_ids = [f"user_{i}" for i in range(1, 11)]

        # Possible activity types
        activity_types = ["login", "logout", "file_access", "database_query",
                         "config_change", "api_access", "report_generation"]

        # Possible resources
        resources = ["/data/customer", "/data/financial", "/data/audit",
                     "/config/system", "/api/v1/transactions", "/reports/monthly"]

        # Possible locations
        locations = ["Office", "Remote", "Branch", "Mobile"]

        # Possible device types
        device_types = ["Desktop", "Laptop", "Mobile", "Tablet"]

        data_batch = []
        for _ in range(num_records):
            # Generate user ID
            user_id = np.random.choice(user_ids)

            # Generate activity type
            activity_type = np.random.choice(activity_types)

            # Generate resource
            resource = np.random.choice(resources)

            # Generate location
            location = np.random.choice(locations)

            # Generate device type
            device_type = np.random.choice(device_types)

            # Generate timestamp
            timestamp = datetime.now().isoformat()

            # Generate success/failure
            success = np.random.random() < 0.95  # 95% success rate

            # Create record
            record = {
                "timestamp": timestamp,
                "user_id": user_id,
                "activity_type": activity_type,
                "resource": resource,
                "location": location,
                "device_type": device_type,
                "success": success,
                "duration": np.random.uniform(0.5, 10.0) if success else 0.0,
                "access_time": datetime.now().strftime("%H:%M:%S")
            }

            data_batch.append(record)

        return data_batch

    def _process_data(self, data_batch: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Process user behavior data"""
        processed_batch = []

        for record in data_batch:
            # Enrich data with additional information
            enriched_record = record.copy()

            # Add user profile information if available
            user_id = record["user_id"]
            if user_id in self.user_profiles:
                profile = self.user_profiles[user_id]
                enriched_record["department"] = profile.get("department")
                enriched_record["role"] = profile.get("role")
                enriched_record["access_level"] = profile.get("access_level")
            else:
                # Generate profile for new user
                departments = ["IT", "Finance", "HR", "Operations", "Legal", "Executive"]
                roles = ["Admin", "Manager", "Analyst", "Developer", "Auditor", "Executive"]
                access_levels = ["Low", "Medium", "High", "Admin"]

                profile = {
                    "department": np.random.choice(departments),
                    "role": np.random.choice(roles),
                    "access_level": np.random.choice(access_levels),
                    "created_at": datetime.now().isoformat()
                }

                self.user_profiles[user_id] = profile

                enriched_record["department"] = profile["department"]
                enriched_record["role"] = profile["role"]
                enriched_record["access_level"] = profile["access_level"]

            # Add data type
            enriched_record["data_type"] = "user"

            processed_batch.append(enriched_record)

        return processed_batch

class EndpointMonitor(DataCollector):
    """Monitors endpoint activities and security status"""

    def __init__(self):
        super().__init__("Endpoint")
        self.collection_interval = 15  # seconds
        self.endpoint_profiles = {}  # endpoint_id -> profile data

    def _collection_loop(self):
        """Collect endpoint data"""
        while self.running:
            try:
                # In a real implementation, this would interface with endpoint monitoring tools
                # For simulation, we'll generate synthetic data
                data_batch = self._generate_synthetic_data()

                # Add to processing queue
                self.data_queue.put(data_batch)

                # Wait for next collection interval
                time.sleep(self.collection_interval)

            except Exception as e:
                logger.error(f"Error collecting endpoint data: {str(e)}")
                time.sleep(self.collection_interval)

    def _generate_synthetic_data(self) -> List[Dict[str, Any]]:
        """Generate synthetic endpoint data for simulation"""
        # Number of records to generate
        num_records = np.random.randint(5, 12)

        # Possible endpoint IDs
        endpoint_ids = [f"endpoint_{i}" for i in range(1, 21)]

        # Possible endpoint types
        endpoint_types = ["Workstation", "Laptop", "Server", "Mobile"]

        # Possible OS types
        os_types = ["Windows 10", "Windows 11", "macOS", "Linux", "iOS", "Android"]

        # Possible statuses
        statuses = ["Online", "Offline", "Sleep", "Updating"]

        # Possible AV statuses
        av_statuses = ["Updated", "Outdated", "Disabled", "Error"]

        # Possible patch statuses
        patch_statuses = ["UpToDate", "PendingUpdates", "CriticalUpdatesNeeded"]

        data_batch = []
        for _ in range(num_records):
            # Generate endpoint ID
            endpoint_id = np.random.choice(endpoint_ids)

            # Check if we have a profile for this endpoint
            if endpoint_id in self.endpoint_profiles:
                profile = self.endpoint_profiles[endpoint_id]
                endpoint_type = profile["endpoint_type"]
                os = profile["os"]
            else:
                # Generate new profile
                endpoint_type = np.random.choice(endpoint_types)
                os = np.random.choice(os_types)

                profile = {
                    "endpoint_type": endpoint_type,
                    "os": os,
                    "created_at": datetime.now().isoformat()
                }

                self.endpoint_profiles[endpoint_id] = profile

            # Generate status
            status = np.random.choice(statuses, p=[0.8, 0.1, 0.05, 0.05])  # 80% online

            # Skip offline endpoints
            if status == "Offline":
                continue

            # Generate AV status
            av_status = np.random.choice(av_statuses, p=[0.85, 0.1, 0.03, 0.02])  # 85% updated

            # Generate patch status
            patch_status = np.random.choice(patch_statuses, p=[0.7, 0.25, 0.05])  # 70% up to date

            # Generate resource usage
            cpu_usage = np.random.uniform(10, 90)
            memory_usage = np.random.uniform(20, 80)
            disk_usage = np.random.uniform(30, 90)

            # Generate timestamp
            timestamp = datetime.now().isoformat()

            # Create record
            record = {
                "timestamp": timestamp,
                "endpoint_id": endpoint_id,
                "endpoint_type": endpoint_type,
                "os": os,
                "status": status,
                "av_status": av_status,
                "patch_status": patch_status,
                "cpu_usage": cpu_usage,
                "memory_usage": memory_usage,
                "disk_usage": disk_usage,
                "process_count": np.random.randint(50, 200),
                "connection_count": np.random.randint(5, 50)
            }

            data_batch.append(record)

        return data_batch

    def _process_data(self, data_batch: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Process endpoint data"""
        processed_batch = []

        for record in data_batch:
            # Enrich data with additional information
            enriched_record = record.copy()

            # Add risk score based on various factors
            risk_score = 0.0

            # Factor: AV status
            if record["av_status"] == "Updated":
                risk_score += 0.0
            elif record["av_status"] == "Outdated":
                risk_score += 2.0
            elif record["av_status"] == "Disabled":
                risk_score += 5.0
            elif record["av_status"] == "Error":
                risk_score += 3.0

            # Factor: Patch status
            if record["patch_status"] == "UpToDate":
                risk_score += 0.0
            elif record["patch_status"] == "PendingUpdates":
                risk_score += 1.0
            elif record["patch_status"] == "CriticalUpdatesNeeded":
                risk_score += 4.0

            # Factor: Resource usage
            if record["cpu_usage"] > 90:
                risk_score += 2.0
            elif record["cpu_usage"] > 80:
                risk_score += 1.0

            if record["memory_usage"] > 90:
                risk_score += 2.0
            elif record["memory_usage"] > 80:
                risk_score += 1.0

            if record["disk_usage"] > 95:
                risk_score += 3.0
            elif record["disk_usage"] > 90:
                risk_score += 2.0
            elif record["disk_usage"] > 80:
                risk_score += 1.0

            # Add risk score to record
            enriched_record["risk_score"] = risk_score

            # Add risk level
            if risk_score >= 8.0:
                enriched_record["risk_level"] = "High"
            elif risk_score >= 4.0:
                enriched_record["risk_level"] = "Medium"
            else:
                enriched_record["risk_level"] = "Low"

            # Add data type
            enriched_record["data_type"] = "endpoint"

            processed_batch.append(enriched_record)

        return processed_batch

class EmailMonitor(DataCollector):
    """Monitors email traffic for phishing attempts"""

    def __init__(self):
        super().__init__("Email")
        self.collection_interval = 20  # seconds

    def _collection_loop(self):
        """Collect email data"""
        while self.running:
            try:
                # In a real implementation, this would interface with email gateway
                # For simulation, we'll generate synthetic data
                data_batch = self._generate_synthetic_data()

                # Add to processing queue
                self.data_queue.put(data_batch)

                # Wait for next collection interval
                time.sleep(self.collection_interval)

            except Exception as e:
                logger.error(f"Error collecting email data: {str(e)}")
                time.sleep(self.collection_interval)

    def _generate_synthetic_data(self) -> List[Dict[str, Any]]:
        """Generate synthetic email data for simulation"""
        # Number of records to generate
        num_records = np.random.randint(2, 8)

        # Possible recipient domains
        recipient_domains = ["company.com", "company.ie", "subsidiary.com"]

        # Possible sender domains (legitimate)
        legitimate_domains = ["partner.com", "vendor.com", "client.com", "gmail.com", "outlook.com"]

        # Possible sender domains (suspicious)
        suspicious_domains = ["partnner.com", "vend0r.com", "c1ient.com", "gmai1.com", "0utlook.com"]

        # Possible subjects (legitimate)
        legitimate_subjects = [
            "Meeting agenda for tomorrow",
            "Project update: Phase 2 complete",
            "Quarterly report attached",
            "New product launch details",
            "Team lunch next week"
        ]

        # Possible subjects (suspicious)
        suspicious_subjects = [
            "Urgent: Your account will be suspended",
            "Action Required: Verify your account details",
            "Security Alert: Unusual activity detected",
            "Password Reset Required Immediately",
            "Important: Update your payment information"
        ]

        data_batch = []
        for _ in range(num_records):
            # Determine if this is a suspicious email (10% chance)
            is_suspicious = np.random.random() < 0.1

            # Generate recipient
            recipient_domain = np.random.choice(recipient_domains)
            recipient = f"user{np.random.randint(1, 100)}@{recipient_domain}"

            # Generate sender
            if is_suspicious:
                sender_domain = np.random.choice(suspicious_domains)
                sender_name = np.random.choice(["admin", "security", "support", "service", "noreply"])
            else:
                sender_domain = np.random.choice(legitimate_domains)
                sender_name = np.random.choice(["john", "jane", "info", "contact", "sales"])

            sender = f"{sender_name}@{sender_domain}"

            # Generate subject
            if is_suspicious:
                subject = np.random.choice(suspicious_subjects)
            else:
                subject = np.random.choice(legitimate_subjects)

            # Generate timestamp
            timestamp = datetime.now().isoformat()

            # Generate attachment info
            has_attachment = np.random.random() < 0.3  # 30% chance of attachment
            attachment_type = None
            if has_attachment:
                if is_suspicious:
                    attachment_type = np.random.choice(["exe", "zip", "js", "vbs", "pdf"])
                else:
                    attachment_type = np.random.choice(["pdf", "docx", "xlsx", "pptx", "txt"])

            # Generate URL info
            contains_url = np.random.random() < 0.5  # 50% chance of URL
            url_domain = None
            if contains_url:
                if is_suspicious:
                    url_domain = np.random.choice(["bit.ly", "tinyurl.com", "goo.gl", "t.co", "ow.ly"])
                else:
                    url_domain = np.random.choice(["company.com", "partner.com", "vendor.com", "client.com"])

            # Create record
            record = {
                "timestamp": timestamp,
                "sender": sender,
                "recipient": recipient,
                "subject": subject,
                "has_attachment": has_attachment,
                "attachment_type": attachment_type,
                "contains_url": contains_url,
                "url_domain": url_domain,
                "size": np.random.randint(1, 1000)  # KB
            }

            data_batch.append(record)

        return data_batch

    def _process_data(self, data_batch: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Process email data"""
        processed_batch = []

        for record in data_batch:
            # Enrich data with additional information
            enriched_record = record.copy()

            # Calculate phishing score
            phishing_score = 0.0

            # Factor: Sender domain
            sender = record["sender"]
            sender_domain = sender.split("@")[-1] if "@" in sender else ""

            suspicious_domains = ["partnner.com", "vend0r.com", "c1ient.com", "gmai1.com", "0utlook.com"]
            if sender_domain in suspicious_domains:
                phishing_score += 3.0

            # Check for lookalike domains
            legitimate_domains = ["partner.com", "vendor.com", "client.com", "gmail.com", "outlook.com"]
            for domain in legitimate_domains:
                if sender_domain != domain and self._is_lookalike(sender_domain, domain):
                    phishing_score += 2.5
                    break

            # Factor: Subject
            subject = record["subject"]
            suspicious_keywords = ["urgent", "alert", "verify", "account", "password", "security",
                                  "update", "confirm", "suspended", "unusual", "immediately"]

            keyword_count = sum(1 for keyword in suspicious_keywords if keyword.lower() in subject.lower())
            phishing_score += keyword_count * 0.5

            # Factor: Attachment
            if record["has_attachment"] and record["attachment_type"] in ["exe", "zip", "js", "vbs"]:
                phishing_score += 3.0

            # Factor: URL
            if record["contains_url"] and record["url_domain"] in ["bit.ly", "tinyurl.com", "goo.gl", "t.co", "ow.ly"]:
                phishing_score += 1.5

            # Add phishing score to record
            enriched_record["phishing_score"] = phishing_score

            # Add phishing probability
            if phishing_score >= 5.0:
                enriched_record["phishing_probability"] = "High"
            elif phishing_score >= 2.0:
                enriched_record["phishing_probability"] = "Medium"
            else:
                enriched_record["phishing_probability"] = "Low"

            # Add data type
            enriched_record["data_type"] = "email"

            processed_batch.append(enriched_record)

        return processed_batch

    def _is_lookalike(self, domain1: str, domain2: str) -> bool:
        """Check if domain1 is a lookalike of domain2"""
        if domain1 == domain2:
            return False

        # Check for character substitution (e.g., 0 for o, 1 for l)
        substitutions = {
            "0": "o",
            "1": "l",
            "5": "s",
            "3": "e"
        }

        domain1_norm = domain1.lower()
        for char, subst in substitutions.items():
            domain1_norm = domain1_norm.replace(char, subst)

        if domain1_norm == domain2.lower():
            return True

        # Check for small differences (e.g., extra letter)
        if len(domain1) == len(domain2) + 1 or len(domain1) == len(domain2) - 1:
            # Calculate Levenshtein distance
            if self._levenshtein_distance(domain1.lower(), domain2.lower()) <= 1:
                return True

        return False

    def _levenshtein_distance(self, s1: str, s2: str) -> int:
        """Calculate Levenshtein distance between two strings"""
        if len(s1) < len(s2):
            return self._levenshtein_distance(s2, s1)

        if len(s2) == 0:
            return len(s1)

        previous_row = range(len(s2) + 1)
        for i, c1 in enumerate(s1):
            current_row = [i + 1]
            for j, c2 in enumerate(s2):
                insertions = previous_row[j + 1] + 1
                deletions = current_row[j] + 1
                substitutions = previous_row[j] + (c1 != c2)
                current_row.append(min(insertions, deletions, substitutions))
            previous_row = current_row

        return previous_row[-1]

class AnomalyDetector:
    """Detects anomalies in collected data using machine learning"""

    def __init__(self):
        self.detectors = {}
        self.baselines = {}
        self.training_data = {}
        self.is_trained = {}
        self.min_training_samples = 50
        logger.info("Initialized anomaly detector")

    def train(self, data_type: str, data: List[Dict[str, Any]]) -> bool:
        """Train the anomaly detector for a specific data type"""
        if len(data) < self.min_training_samples:
            # Not enough data for training
            return False

        try:
            # Store training data
            if data_type not in self.training_data:
                self.training_data[data_type] = []

            self.training_data[data_type].extend(data)

            # Limit training data size
            max_training_samples = 1000
            if len(self.training_data[data_type]) > max_training_samples:
                self.training_data[data_type] = self.training_data[data_type][-max_training_samples:]

            # Extract features for training
            features = self._extract_features(data_type, self.training_data[data_type])

            if features.size == 0:
                return False

            # Train isolation forest model
            from sklearn.ensemble import IsolationForest

            model = IsolationForest(n_estimators=100, contamination=0.05, random_state=42)
            model.fit(features)

            # Store the model
            self.detectors[data_type] = model

            # Calculate baseline statistics
            self.baselines[data_type] = {
                "mean": features.mean(axis=0),
                "std": features.std(axis=0),
                "min": features.min(axis=0),
                "max": features.max(axis=0)
            }

            self.is_trained[data_type] = True
            logger.info(f"Trained anomaly detector for {data_type} data with {len(data)} samples")

            return True

        except Exception as e:
            logger.error(f"Error training anomaly detector for {data_type} data: {str(e)}")
            return False

    def detect(self, data_type: str, data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Detect anomalies in the data"""
        if data_type not in self.is_trained or not self.is_trained[data_type]:
            # Not trained yet, train with this data
            self.train(data_type, data)
            return []  # No anomalies during initial training

        try:
            # Extract features for detection
            features = self._extract_features(data_type, data)

            if features.size == 0:
                return []

            # Get the model
            model = self.detectors[data_type]

            # Predict anomalies
            predictions = model.predict(features)
            scores = model.decision_function(features)

            # Find anomalies (prediction == -1)
            anomalies = []
            for i, (pred, score) in enumerate(zip(predictions, scores)):
                if pred == -1:  # Anomaly
                    anomaly_data = data[i].copy()
                    anomaly_data["anomaly_score"] = float(score)
                    anomaly_data["anomaly_features"] = self._get_anomalous_features(data_type, data[i])
                    anomalies.append(anomaly_data)

            if anomalies:
                logger.info(f"Detected {len(anomalies)} anomalies in {data_type} data")

            return anomalies

        except Exception as e:
            logger.error(f"Error detecting anomalies in {data_type} data: {str(e)}")
            return []

    def _extract_features(self, data_type: str, data: List[Dict[str, Any]]) -> np.ndarray:
        """Extract features from data for anomaly detection"""
        if not data:
            return np.array([])

        if data_type == "network":
            # Extract network features
            features = []
            for record in data:
                # Basic features
                record_features = [
                    record.get("bytes_sent", 0),
                    record.get("bytes_received", 0),
                    record.get("duration", 0),
                    record.get("packets", 0)
                ]

                # Derived features
                bytes_total = record.get("bytes_sent", 0) + record.get("bytes_received", 0)
                packets = max(record.get("packets", 1), 1)  # Avoid division by zero
                duration = max(record.get("duration", 0.1), 0.1)  # Avoid division by zero

                bytes_per_packet = bytes_total / packets
                bytes_per_second = bytes_total / duration
                packets_per_second = packets / duration

                record_features.extend([bytes_per_packet, bytes_per_second, packets_per_second])

                features.append(record_features)

            return np.array(features)

        elif data_type == "user":
            # Extract user behavior features
            features = []
            for record in data:
                # Convert categorical features to numeric
                activity_type_map = {
                    "login": 1,
                    "logout": 2,
                    "file_access": 3,
                    "database_query": 4,
                    "config_change": 5,
                    "api_access": 6,
                    "report_generation": 7
                }

                location_map = {
                    "Office": 1,
                    "Remote": 2,
                    "Branch": 3,
                    "Mobile": 4
                }

                device_type_map = {
                    "Desktop": 1,
                    "Laptop": 2,
                    "Mobile": 3,
                    "Tablet": 4
                }

                # Extract time features
                access_time = record.get("access_time", "00:00:00")
                try:
                    hours, minutes, seconds = map(int, access_time.split(":"))
                    time_value = hours + minutes/60 + seconds/3600  # Convert to decimal hours
                except:
                    time_value = 0

                # Basic features
                record_features = [
                    activity_type_map.get(record.get("activity_type"), 0),
                    location_map.get(record.get("location"), 0),
                    device_type_map.get(record.get("device_type"), 0),
                    1 if record.get("success", True) else 0,
                    record.get("duration", 0),
                    time_value
                ]

                features.append(record_features)

            return np.array(features)

        elif data_type == "endpoint":
            # Extract endpoint features
            features = []
            for record in data:
                # Convert categorical features to numeric
                status_map = {
                    "Online": 1,
                    "Offline": 0,
                    "Sleep": 0.5,
                    "Updating": 0.8
                }

                av_status_map = {
                    "Updated": 1,
                    "Outdated": 0.5,
                    "Disabled": 0,
                    "Error": 0.2
                }

                patch_status_map = {
                    "UpToDate": 1,
                    "PendingUpdates": 0.7,
                    "CriticalUpdatesNeeded": 0.3
                }

                # Basic features
                record_features = [
                    status_map.get(record.get("status"), 0),
                    av_status_map.get(record.get("av_status"), 0),
                    patch_status_map.get(record.get("patch_status"), 0),
                    record.get("cpu_usage", 0) / 100,  # Normalize to 0-1
                    record.get("memory_usage", 0) / 100,  # Normalize to 0-1
                    record.get("disk_usage", 0) / 100,  # Normalize to 0-1
                    record.get("process_count", 0) / 200,  # Normalize to approximate 0-1
                    record.get("connection_count", 0) / 50  # Normalize to approximate 0-1
                ]

                features.append(record_features)

            return np.array(features)

        elif data_type == "email":
            # Extract email features
            features = []
            for record in data:
                # Basic features
                record_features = [
                    1 if record.get("has_attachment", False) else 0,
                    1 if record.get("contains_url", False) else 0,
                    record.get("size", 0) / 1000  # Normalize to approximate 0-1
                ]

                # Add attachment type feature
                attachment_type = record.get("attachment_type")
                if attachment_type in ["exe", "zip", "js", "vbs"]:
                    record_features.append(1)  # High risk
                elif attachment_type in ["pdf"]:
                    record_features.append(0.5)  # Medium risk
                elif attachment_type in ["docx", "xlsx", "pptx"]:
                    record_features.append(0.3)  # Low risk
                elif attachment_type in ["txt", "jpg", "png"]:
                    record_features.append(0.1)  # Very low risk
                else:
                    record_features.append(0)  # No attachment

                # Add URL domain feature
                url_domain = record.get("url_domain")
                if url_domain in ["bit.ly", "tinyurl.com", "goo.gl", "t.co", "ow.ly"]:
                    record_features.append(1)  # High risk
                elif url_domain in ["gmail.com", "outlook.com", "yahoo.com"]:
                    record_features.append(0.3)  # Low risk
                elif url_domain in ["company.com", "partner.com", "vendor.com", "client.com"]:
                    record_features.append(0.1)  # Very low risk
                else:
                    record_features.append(0.5)  # Medium risk or no URL

                # Add phishing score if available
                if "phishing_score" in record:
                    record_features.append(min(record["phishing_score"] / 10, 1))  # Normalize to 0-1
                else:
                    record_features.append(0)

                features.append(record_features)

            return np.array(features)

        else:
            # Unknown data type
            logger.warning(f"Unknown data type for feature extraction: {data_type}")
            return np.array([])

    def _get_anomalous_features(self, data_type: str, record: Dict[str, Any]) -> Dict[str, Any]:
        """Identify which features are anomalous in a record"""
        if data_type not in self.baselines:
            return {}

        baseline = self.baselines[data_type]
        anomalous_features = {}

        if data_type == "network":
            # Check network features
            if record.get("bytes_sent", 0) > baseline["mean"][0] + 3 * baseline["std"][0]:
                anomalous_features["bytes_sent"] = record.get("bytes_sent", 0)

            if record.get("bytes_received", 0) > baseline["mean"][1] + 3 * baseline["std"][1]:
                anomalous_features["bytes_received"] = record.get("bytes_received", 0)

            if record.get("duration", 0) > baseline["mean"][2] + 3 * baseline["std"][2]:
                anomalous_features["duration"] = record.get("duration", 0)

            if record.get("packets", 0) > baseline["mean"][3] + 3 * baseline["std"][3]:
                anomalous_features["packets"] = record.get("packets", 0)

        elif data_type == "user":
            # Check user behavior features
            if record.get("duration", 0) > baseline["mean"][4] + 3 * baseline["std"][4]:
                anomalous_features["duration"] = record.get("duration", 0)

            # Check time of access
            access_time = record.get("access_time", "00:00:00")
            try:
                hours, minutes, seconds = map(int, access_time.split(":"))
                time_value = hours + minutes/60 + seconds/3600  # Convert to decimal hours

                # Check for unusual access times (e.g., late night)
                if hours < 6 or hours > 20:  # Before 6 AM or after 8 PM
                    anomalous_features["access_time"] = access_time
            except:
                pass

            # Check for unusual location/device combinations
            if record.get("location") == "Remote" and record.get("device_type") == "Desktop":
                anomalous_features["location_device"] = f"{record.get('location')}/{record.get('device_type')}"

        elif data_type == "endpoint":
            # Check endpoint features
            if record.get("cpu_usage", 0) > baseline["mean"][3] + 3 * baseline["std"][3] * 100:
                anomalous_features["cpu_usage"] = record.get("cpu_usage", 0)

            if record.get("memory_usage", 0) > baseline["mean"][4] + 3 * baseline["std"][4] * 100:
                anomalous_features["memory_usage"] = record.get("memory_usage", 0)

            if record.get("disk_usage", 0) > baseline["mean"][5] + 3 * baseline["std"][5] * 100:
                anomalous_features["disk_usage"] = record.get("disk_usage", 0)

            if record.get("process_count", 0) > baseline["mean"][6] + 3 * baseline["std"][6] * 200:
                anomalous_features["process_count"] = record.get("process_count", 0)

            if record.get("connection_count", 0) > baseline["mean"][7] + 3 * baseline["std"][7] * 50:
                anomalous_features["connection_count"] = record.get("connection_count", 0)

            # Check for disabled AV
            if record.get("av_status") == "Disabled":
                anomalous_features["av_status"] = record.get("av_status")

            # Check for critical updates needed
            if record.get("patch_status") == "CriticalUpdatesNeeded":
                anomalous_features["patch_status"] = record.get("patch_status")

        elif data_type == "email":
            # Check email features
            if record.get("phishing_score", 0) > 5.0:
                anomalous_features["phishing_score"] = record.get("phishing_score", 0)

            # Check for suspicious attachments
            if record.get("has_attachment", False) and record.get("attachment_type") in ["exe", "zip", "js", "vbs"]:
                anomalous_features["attachment_type"] = record.get("attachment_type")

            # Check for suspicious URLs
            if record.get("contains_url", False) and record.get("url_domain") in ["bit.ly", "tinyurl.com", "goo.gl", "t.co", "ow.ly"]:
                anomalous_features["url_domain"] = record.get("url_domain")

        return anomalous_features

class ThreatClassifier:
    """Classifies detected anomalies into specific threat types"""

    def __init__(self):
        logger.info("Initialized threat classifier")

    def classify(self, data_type: str, anomaly_data: Dict[str, Any]) -> Dict[str, Any]:
        """Classify an anomaly into a specific threat type"""
        try:
            # Initialize threat data
            threat_data = {
                "timestamp": datetime.now().isoformat(),
                "data_type": data_type,
                "anomaly_data": anomaly_data,
                "threat_type": "unknown",
                "severity": "low",
                "confidence": 0.0
            }

            # Classify based on data type
            if data_type == "network":
                self._classify_network_threat(threat_data)
            elif data_type == "user":
                self._classify_user_threat(threat_data)
            elif data_type == "endpoint":
                self._classify_endpoint_threat(threat_data)
            elif data_type == "email":
                self._classify_email_threat(threat_data)

            # Log the classification
            logger.info(f"Classified {data_type} anomaly as {threat_data['threat_type']} threat with {threat_data['confidence']:.2f} confidence")

            return threat_data

        except Exception as e:
            logger.error(f"Error classifying {data_type} anomaly: {str(e)}")
            return {
                "timestamp": datetime.now().isoformat(),
                "data_type": data_type,
                "anomaly_data": anomaly_data,
                "threat_type": "unknown",
                "severity": "low",
                "confidence": 0.0,
                "error": str(e)
            }

    def _classify_network_threat(self, threat_data: Dict[str, Any]) -> None:
        """Classify network-based threats"""
        anomaly_data = threat_data["anomaly_data"]
        anomalous_features = anomaly_data.get("anomaly_features", {})

        # Check for DoS attack
        dos_indicators = 0
        if "bytes_sent" in anomalous_features or "bytes_received" in anomalous_features:
            dos_indicators += 1
        if "packets" in anomalous_features:
            dos_indicators += 1
        if anomaly_data.get("protocol") == "TCP" and anomaly_data.get("flags") == "S":
            dos_indicators += 1  # Potential SYN flood

        # Check for MitM attack
        mitm_indicators = 0
        if anomaly_data.get("protocol") in ["HTTP", "HTTPS"]:
            mitm_indicators += 1
        if anomaly_data.get("dst_port") in [80, 443]:
            mitm_indicators += 1

        # Determine threat type
        if dos_indicators >= 2:
            threat_data["threat_type"] = "dos"
            threat_data["confidence"] = min(0.5 + dos_indicators * 0.15, 0.95)

            # Determine severity
            if "packets" in anomalous_features and anomaly_data.get("packets", 0) > 1000:
                threat_data["severity"] = "high"
            elif "bytes_sent" in anomalous_features or "bytes_received" in anomalous_features:
                threat_data["severity"] = "medium"
            else:
                threat_data["severity"] = "low"

        elif mitm_indicators >= 2:
            threat_data["threat_type"] = "mitm"
            threat_data["confidence"] = min(0.4 + mitm_indicators * 0.15, 0.9)

            # Determine severity
            if anomaly_data.get("service") == "HTTPS":
                threat_data["severity"] = "high"
            else:
                threat_data["severity"] = "medium"

        else:
            # Generic network threat
            threat_data["threat_type"] = "network_anomaly"
            threat_data["confidence"] = 0.6
            threat_data["severity"] = "low"

    def _classify_user_threat(self, threat_data: Dict[str, Any]) -> None:
        """Classify user-based threats"""
        anomaly_data = threat_data["anomaly_data"]
        anomalous_features = anomaly_data.get("anomaly_features", {})

        # Check for insider threat
        insider_indicators = 0
        if "access_time" in anomalous_features:
            insider_indicators += 1  # Unusual access time
        if "location_device" in anomalous_features:
            insider_indicators += 1  # Unusual location/device combination
        if anomaly_data.get("activity_type") in ["file_access", "database_query"] and "duration" in anomalous_features:
            insider_indicators += 1  # Unusual duration for data access
        if anomaly_data.get("activity_type") == "config_change":
            insider_indicators += 1  # Configuration changes are sensitive

        # Determine threat type
        if insider_indicators >= 1:
            threat_data["threat_type"] = "insider_threat"
            threat_data["confidence"] = min(0.4 + insider_indicators * 0.15, 0.9)

            # Determine severity
            if insider_indicators >= 3:
                threat_data["severity"] = "high"
            elif insider_indicators >= 2:
                threat_data["severity"] = "medium"
            else:
                threat_data["severity"] = "low"

        else:
            # Generic user anomaly
            threat_data["threat_type"] = "user_anomaly"
            threat_data["confidence"] = 0.5
            threat_data["severity"] = "low"

    def _classify_endpoint_threat(self, threat_data: Dict[str, Any]) -> None:
        """Classify endpoint-based threats"""
        anomaly_data = threat_data["anomaly_data"]
        anomalous_features = anomaly_data.get("anomaly_features", {})

        # Check for ransomware
        ransomware_indicators = 0
        if "cpu_usage" in anomalous_features and anomaly_data.get("cpu_usage", 0) > 80:
            ransomware_indicators += 1
        if "disk_usage" in anomalous_features:
            ransomware_indicators += 1
        if anomaly_data.get("av_status") == "Disabled":
            ransomware_indicators += 2  # Stronger indicator

        # Check for malware
        malware_indicators = 0
        if "process_count" in anomalous_features:
            malware_indicators += 1
        if "connection_count" in anomalous_features:
            malware_indicators += 1
        if anomaly_data.get("patch_status") == "CriticalUpdatesNeeded":
            malware_indicators += 1

        # Determine threat type
        if ransomware_indicators >= 2:
            threat_data["threat_type"] = "ransomware"
            threat_data["confidence"] = min(0.5 + ransomware_indicators * 0.15, 0.95)

            # Determine severity
            if ransomware_indicators >= 3:
                threat_data["severity"] = "high"
            elif ransomware_indicators >= 2:
                threat_data["severity"] = "medium"
            else:
                threat_data["severity"] = "low"

        elif malware_indicators >= 2:
            threat_data["threat_type"] = "malware"
            threat_data["confidence"] = min(0.4 + malware_indicators * 0.15, 0.9)

            # Determine severity
            if malware_indicators >= 3:
                threat_data["severity"] = "high"
            elif malware_indicators >= 2:
                threat_data["severity"] = "medium"
            else:
                threat_data["severity"] = "low"

        else:
            # Generic endpoint anomaly
            threat_data["threat_type"] = "endpoint_anomaly"
            threat_data["confidence"] = 0.5
            threat_data["severity"] = "low"

    def _classify_email_threat(self, threat_data: Dict[str, Any]) -> None:
        """Classify email-based threats"""
        anomaly_data = threat_data["anomaly_data"]
        anomalous_features = anomaly_data.get("anomaly_features", {})

        # Check for phishing
        phishing_indicators = 0
        if "phishing_score" in anomalous_features:
            phishing_score = anomalous_features["phishing_score"]
            if phishing_score > 7.5:
                phishing_indicators += 3  # Strong indicator
            elif phishing_score > 5.0:
                phishing_indicators += 2  # Moderate indicator
            elif phishing_score > 2.5:
                phishing_indicators += 1  # Weak indicator

        if "attachment_type" in anomalous_features:
            phishing_indicators += 2  # Suspicious attachment

        if "url_domain" in anomalous_features:
            phishing_indicators += 1  # Suspicious URL

        # Determine threat type
        if phishing_indicators >= 1:
            threat_data["threat_type"] = "phishing"
            threat_data["confidence"] = min(0.4 + phishing_indicators * 0.15, 0.95)

            # Determine severity
            if phishing_indicators >= 3:
                threat_data["severity"] = "high"
            elif phishing_indicators >= 2:
                threat_data["severity"] = "medium"
            else:
                threat_data["severity"] = "low"

        else:
            # Generic email anomaly
            threat_data["threat_type"] = "email_anomaly"
            threat_data["confidence"] = 0.5
            threat_data["severity"] = "low"

class MonitoringSystem:
    """Main monitoring system that coordinates all components"""

    def __init__(self):
        # Initialize collectors
        self.collectors = {
            "network": NetworkTrafficCollector(),
            "user": UserBehaviorMonitor(),
            "endpoint": EndpointMonitor(),
            "email": EmailMonitor()
        }

        # Initialize anomaly detector
        self.anomaly_detector = AnomalyDetector()

        # Initialize threat classifier
        self.threat_classifier = ThreatClassifier()

        # Initialize data stores
        self.anomalies = []
        self.threats = []

        # Initialize system state
        self.running = False
        self.analysis_interval = 10  # seconds

        logger.info("Initialized monitoring system")

    def start(self):
        """Start the monitoring system"""
        if not self.running:
            self.running = True

            # Start collectors
            for collector_name, collector in self.collectors.items():
                collector.start()

            # Start analysis thread
            self.analysis_thread = threading.Thread(target=self._analysis_loop)
            self.analysis_thread.daemon = True
            self.analysis_thread.start()

            logger.info("Started monitoring system")

    def stop(self):
        """Stop the monitoring system"""
        if self.running:
            self.running = False

            # Stop collectors
            for collector_name, collector in self.collectors.items():
                collector.stop()

            logger.info("Stopped monitoring system")

    def _analysis_loop(self):
        """Main analysis loop"""
        while self.running:
            try:
                # Analyze data from each collector
                for collector_name, collector in self.collectors.items():
                    # Get recent data
                    recent_data = collector.get_recent_data(100)

                    if not recent_data:
                        continue

                    # Detect anomalies
                    anomalies = self.anomaly_detector.detect(collector_name, recent_data)

                    if anomalies:
                        # Store anomalies
                        self.anomalies.extend(anomalies)

                        # Limit stored anomalies
                        max_anomalies = 1000
                        if len(self.anomalies) > max_anomalies:
                            self.anomalies = self.anomalies[-max_anomalies:]

                        # Classify anomalies as threats
                        for anomaly in anomalies:
                            threat = self.threat_classifier.classify(collector_name, anomaly)

                            # Only store significant threats
                            if threat["confidence"] >= 0.6:
                                self.threats.append(threat)

                                # Limit stored threats
                                max_threats = 1000
                                if len(self.threats) > max_threats:
                                    self.threats = self.threats[-max_threats:]

                # Wait for next analysis interval
                time.sleep(self.analysis_interval)

            except Exception as e:
                logger.error(f"Error in analysis loop: {str(e)}")
                time.sleep(self.analysis_interval)

    def get_status(self) -> Dict[str, Any]:
        """Get current status of the monitoring system"""
        # Count data by type
        data_counts = {}
        for collector_name, collector in self.collectors.items():
            data_counts[collector_name] = len(collector.processed_data)

        # Count anomalies by type
        anomaly_counts = {}
        for anomaly in self.anomalies:
            data_type = anomaly.get("data_type")
            if data_type in anomaly_counts:
                anomaly_counts[data_type] += 1
            else:
                anomaly_counts[data_type] = 1

        # Count threats by type
        threat_counts = {}
        for threat in self.threats:
            threat_type = threat.get("threat_type")
            if threat_type in threat_counts:
                threat_counts[threat_type] += 1
            else:
                threat_counts[threat_type] = 1

        return {
            "running": self.running,
            "data_counts": data_counts,
            "anomaly_counts": anomaly_counts,
            "threat_counts": threat_counts,
            "anomaly_count": len(self.anomalies),
            "threat_count": len(self.threats)
        }

    def get_recent_anomalies(self, count: int = 10) -> List[Dict[str, Any]]:
        """Get the most recent anomalies"""
        return self.anomalies[-count:] if self.anomalies else []

    def get_recent_threats(self, count: int = 10) -> List[Dict[str, Any]]:
        """Get the most recent threats"""
        return self.threats[-count:] if self.threats else []

# Example usage
if __name__ == "__main__":
    # Initialize and start the monitoring system
    monitoring_system = MonitoringSystem()
    monitoring_system.start()

    try:
        # Run for a while to demonstrate
        for _ in range(5):
            time.sleep(60)
            status = monitoring_system.get_status()
            print(f"Status: {json.dumps(status, indent=2)}")

            # Print recent threats
            recent_threats = monitoring_system.get_recent_threats(5)
            if recent_threats:
                print(f"\nRecent threats ({len(recent_threats)}):\n")
                for threat in recent_threats:
                    print(f"- {threat['severity'].upper()} severity {threat['threat_type']} threat")
            else:
                print("\nNo threats detected yet\n")

            print("\n" + "-"*50)
    finally:
        # Stop the monitoring system
        monitoring_system.stop()



# Install required dependencies
!pip install pandas numpy scikit-learn matplotlib

"""
Threat Prevention Mechanisms for AI-Powered Threat Detection System

This module implements proactive threat prevention mechanisms that work in conjunction
with the real-time monitoring components to prevent security threats before they impact
financial institution systems.
"""

import logging
import json
import time
import threading
import queue
import numpy as np
from datetime import datetime, timedelta
import ipaddress
import re
import hashlib
import base64
import requests
from typing import Dict, List, Any, Tuple, Optional, Union

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("prevention_system.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger("threat_prevention")

class PreventionAction:
    """Base class for all prevention actions"""

    def __init__(self, name: str):
        """
        Initialize the prevention action

        Args:
            name: Name of the prevention action
        """
        self.name = name
        logger.info(f"Initialized {name} prevention action")

    def execute(self, threat_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Execute the prevention action

        Args:
            threat_data: Data about the detected threat

        Returns:
            Dict containing the result of the action
        """
        raise NotImplementedError("Subclasses must implement execute method")

class NetworkBlocker(PreventionAction):
    """Blocks malicious network traffic"""

    def __init__(self):
        super().__init__("NetworkBlocker")
        self.blocked_ips = set()
        self.blocked_domains = set()
        self.block_duration = 3600  # Default block duration in seconds (1 hour)
        self.temporary_blocks = {}  # IP/domain -> expiration timestamp

    def execute(self, threat_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Block malicious network traffic based on threat data

        Args:
            threat_data: Data about the detected threat

        Returns:
            Dict containing the result of the action
        """
        result = {
            "action": "network_block",
            "success": False,
            "details": {},
            "timestamp": datetime.now().isoformat()
        }

        try:
            # Extract relevant information from threat data
            data_type = threat_data.get("data_type")
            anomaly_data = threat_data.get("anomaly_data", {})
            threat_type = threat_data.get("threat_type")
            severity = threat_data.get("severity")

            # Determine what to block based on data type and threat
            if data_type == "network":
                # Block source IP for network-based threats
                if "src_ip" in anomaly_data:
                    ip = anomaly_data["src_ip"]
                    duration = self._get_block_duration(severity)
                    self._block_ip(ip, duration)
                    result["success"] = True
                    result["details"]["blocked_ip"] = ip
                    result["details"]["duration"] = f"{duration} seconds"
                    logger.info(f"Blocked IP {ip} for {duration} seconds due to {threat_type} threat")

            elif data_type == "email" and "sender" in anomaly_data:
                # Block sender domain for email-based threats
                sender = anomaly_data["sender"]
                domain = sender.split("@")[-1] if "@" in sender else None
                if domain:
                    duration = self._get_block_duration(severity)
                    self._block_domain(domain, duration)
                    result["success"] = True
                    result["details"]["blocked_domain"] = domain
                    result["details"]["duration"] = f"{duration} seconds"
                    logger.info(f"Blocked domain {domain} for {duration} seconds due to {threat_type} threat")

            # Clean up expired blocks
            self._cleanup_expired_blocks()

        except Exception as e:
            logger.error(f"Error executing network block: {str(e)}")
            result["details"]["error"] = str(e)

        return result

    def _get_block_duration(self, severity: str) -> int:
        """
        Determine block duration based on threat severity

        Args:
            severity: Threat severity (low, medium, high)

        Returns:
            Block duration in seconds
        """
        if severity == "high":
            return 24 * 3600  # 24 hours
        elif severity == "medium":
            return 6 * 3600   # 6 hours
        else:
            return 1 * 3600   # 1 hour

    def _block_ip(self, ip: str, duration: int) -> None:
        """
        Block an IP address

        Args:
            ip: IP address to block
            duration: Block duration in seconds
        """
        # In a real implementation, this would interface with firewall/IPS
        # For simulation, we just track the blocked IPs
        self.blocked_ips.add(ip)
        expiration = datetime.now() + timedelta(seconds=duration)
        self.temporary_blocks[ip] = expiration

        # Log the action for audit purposes
        logger.info(f"Blocked IP {ip} until {expiration.isoformat()}")

    def _block_domain(self, domain: str, duration: int) -> None:
        """
        Block a domain

        Args:
            domain: Domain to block
            duration: Block duration in seconds
        """
        # In a real implementation, this would interface with DNS/proxy systems
        # For simulation, we just track the blocked domains
        self.blocked_domains.add(domain)
        expiration = datetime.now() + timedelta(seconds=duration)
        self.temporary_blocks[domain] = expiration

        # Log the action for audit purposes
        logger.info(f"Blocked domain {domain} until {expiration.isoformat()}")

    def _cleanup_expired_blocks(self) -> None:
        """Remove expired blocks"""
        now = datetime.now()
        expired = [item for item, expiration in self.temporary_blocks.items() if expiration <= now]

        for item in expired:
            if item in self.blocked_ips:
                self.blocked_ips.remove(item)
            if item in self.blocked_domains:
                self.blocked_domains.remove(item)
            del self.temporary_blocks[item]

            logger.info(f"Removed expired block for {item}")

    def is_blocked(self, ip_or_domain: str) -> bool:
        """
        Check if an IP or domain is currently blocked

        Args:
            ip_or_domain: IP address or domain to check

        Returns:
            True if blocked, False otherwise
        """
        # Clean up expired blocks first
        self._cleanup_expired_blocks()

        # Check if IP or domain is in blocked lists
        return (ip_or_domain in self.blocked_ips or
                ip_or_domain in self.blocked_domains)

class AccessController(PreventionAction):
    """Controls access to sensitive resources"""

    def __init__(self):
        super().__init__("AccessController")
        self.restricted_users = {}  # user_id -> restrictions
        self.restricted_resources = {}  # resource -> restrictions

    def execute(self, threat_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Implement access control measures based on threat data

        Args:
            threat_data: Data about the detected threat

        Returns:
            Dict containing the result of the action
        """
        result = {
            "action": "access_control",
            "success": False,
            "details": {},
            "timestamp": datetime.now().isoformat()
        }

        try:
            # Extract relevant information from threat data
            data_type = threat_data.get("data_type")
            anomaly_data = threat_data.get("anomaly_data", {})
            threat_type = threat_data.get("threat_type")
            severity = threat_data.get("severity")

            # Handle user-based threats (especially insider threats)
            if data_type == "user" and "user_id" in anomaly_data:
                user_id = anomaly_data["user_id"]

                if threat_type == "insider_threat" or severity == "high":
                    # Implement strict access controls for potential insider threats
                    restrictions = self._get_user_restrictions(severity)
                    self._restrict_user_access(user_id, restrictions)
                    result["success"] = True
                    result["details"]["restricted_user"] = user_id
                    result["details"]["restrictions"] = restrictions
                    logger.info(f"Restricted access for user {user_id} due to {threat_type} threat")

                # If a specific resource is involved, restrict access to it
                if "resource" in anomaly_data:
                    resource = anomaly_data["resource"]
                    restrictions = self._get_resource_restrictions(severity)
                    self._restrict_resource_access(resource, restrictions)
                    result["details"]["restricted_resource"] = resource
                    result["details"]["resource_restrictions"] = restrictions
                    logger.info(f"Restricted access to resource {resource} due to {threat_type} threat")

        except Exception as e:
            logger.error(f"Error executing access control: {str(e)}")
            result["details"]["error"] = str(e)

        return result

    def _get_user_restrictions(self, severity: str) -> Dict[str, Any]:
        """
        Determine user restrictions based on threat severity

        Args:
            severity: Threat severity (low, medium, high)

        Returns:
            Dict of restriction settings
        """
        if severity == "high":
            return {
                "require_mfa": True,
                "restrict_admin_access": True,
                "restrict_sensitive_data": True,
                "additional_monitoring": True,
                "duration": 24 * 3600  # 24 hours
            }
        elif severity == "medium":
            return {
                "require_mfa": True,
                "restrict_admin_access": True,
                "restrict_sensitive_data": False,
                "additional_monitoring": True,
                "duration": 12 * 3600  # 12 hours
            }
        else:
            return {
                "require_mfa": True,
                "restrict_admin_access": False,
                "restrict_sensitive_data": False,
                "additional_monitoring": True,
                "duration": 6 * 3600  # 6 hours
            }

    def _get_resource_restrictions(self, severity: str) -> Dict[str, Any]:
        """
        Determine resource restrictions based on threat severity

        Args:
            severity: Threat severity (low, medium, high)

        Returns:
            Dict of restriction settings
        """
        if severity == "high":
            return {
                "require_approval": True,
                "read_only": True,
                "restrict_download": True,
                "additional_logging": True,
                "duration": 24 * 3600  # 24 hours
            }
        elif severity == "medium":
            return {
                "require_approval": True,
                "read_only": False,
                "restrict_download": True,
                "additional_logging": True,
                "duration": 12 * 3600  # 12 hours
            }
        else:
            return {
                "require_approval": False,
                "read_only": False,
                "restrict_download": False,
                "additional_logging": True,
                "duration": 6 * 3600  # 6 hours
            }

    def _restrict_user_access(self, user_id: str, restrictions: Dict[str, Any]) -> None:
        """
        Apply access restrictions to a user

        Args:
            user_id: User ID to restrict
            restrictions: Restriction settings
        """
        # In a real implementation, this would interface with IAM/access control systems
        # For simulation, we just track the restrictions
        expiration = datetime.now() + timedelta(seconds=restrictions["duration"])
        restrictions["expiration"] = expiration
        self.restricted_users[user_id] = restrictions

        # Log the action for audit purposes
        logger.info(f"Applied access restrictions to user {user_id} until {expiration.isoformat()}")

    def _restrict_resource_access(self, resource: str, restrictions: Dict[str, Any]) -> None:
        """
        Apply access restrictions to a resource

        Args:
            resource: Resource to restrict
            restrictions: Restriction settings
        """
        # In a real implementation, this would interface with resource access control systems
        # For simulation, we just track the restrictions
        expiration = datetime.now() + timedelta(seconds=restrictions["duration"])
        restrictions["expiration"] = expiration
        self.restricted_resources[resource] = restrictions

        # Log the action for audit purposes
        logger.info(f"Applied access restrictions to resource {resource} until {expiration.isoformat()}")

    def check_user_access(self, user_id: str, resource: str = None) -> Dict[str, Any]:
        """
        Check access restrictions for a user

        Args:
            user_id: User ID to check
            resource: Optional resource being accessed

        Returns:
            Dict containing access restrictions
        """
        result = {
            "restricted": False,
            "restrictions": {}
        }

        # Check user restrictions
        if user_id in self.restricted_users:
            restrictions = self.restricted_users[user_id]
            expiration = restrictions.get("expiration")

            if expiration and expiration > datetime.now():
                result["restricted"] = True
                result["restrictions"].update(restrictions)
            else:
                # Remove expired restrictions
                del self.restricted_users[user_id]

        # Check resource restrictions if a resource is specified
        if resource and resource in self.restricted_resources:
            restrictions = self.restricted_resources[resource]
            expiration = restrictions.get("expiration")

            if expiration and expiration > datetime.now():
                result["restricted"] = True
                result["resource_restricted"] = True
                result["resource_restrictions"] = restrictions
            else:
                # Remove expired restrictions
                del self.restricted_resources[resource]

        return result

class EndpointProtector(PreventionAction):
    """Implements endpoint protection measures"""

    def __init__(self):
        super().__init__("EndpointProtector")
        self.isolated_endpoints = {}  # endpoint_id -> isolation details
        self.blocked_processes = set()

    def execute(self, threat_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Implement endpoint protection measures based on threat data

        Args:
            threat_data: Data about the detected threat

        Returns:
            Dict containing the result of the action
        """
        result = {
            "action": "endpoint_protection",
            "success": False,
            "details": {},
            "timestamp": datetime.now().isoformat()
        }

        try:
            # Extract relevant information from threat data
            data_type = threat_data.get("data_type")
            anomaly_data = threat_data.get("anomaly_data", {})
            threat_type = threat_data.get("threat_type")
            severity = threat_data.get("severity")

            # Handle endpoint-based threats
            if data_type == "endpoint" and "endpoint_id" in anomaly_data:
                endpoint_id = anomaly_data["endpoint_id"]

                # For ransomware or malware, isolate the endpoint
                if threat_type in ["ransomware", "malware"] and severity in ["medium", "high"]:
                    isolation_level = "full" if severity == "high" else "partial"
                    self._isolate_endpoint(endpoint_id, isolation_level)
                    result["success"] = True
                    result["details"]["isolated_endpoint"] = endpoint_id
                    result["details"]["isolation_level"] = isolation_level
                    logger.info(f"Isolated endpoint {endpoint_id} ({isolation_level}) due to {threat_type} threat")

                # For any unusual processes, block them
                if "unusual_processes" in anomaly_data and anomaly_data["unusual_processes"] > 0:
                    # In a real implementation, we would have process names
                    # For simulation, we'll use a placeholder
                    process_name = f"suspicious_process_{hash(str(anomaly_data))}"
                    self._block_process(process_name)
                    result["success"] = True
                    result["details"]["blocked_process"] = process_name
                    logger.info(f"Blocked process {process_name} on endpoint {endpoint_id}")

        except Exception as e:
            logger.error(f"Error executing endpoint protection: {str(e)}")
            result["details"]["error"] = str(e)

        return result

    def _isolate_endpoint(self, endpoint_id: str, isolation_level: str) -> None:
        """
        Isolate an endpoint from the network

        Args:
            endpoint_id: Endpoint ID to isolate
            isolation_level: Level of isolation (partial or full)
        """
        # In a real implementation, this would interface with endpoint security solutions
        # For simulation, we just track the isolated endpoints
        isolation_details = {
            "level": isolation_level,
            "timestamp": datetime.now().isoformat(),
            "reason": "Automated response to security threat",
            "allowed_connections": ["security_server"] if isolation_level == "partial" else []
        }

        self.isolated_endpoints[endpoint_id] = isolation_details

        # Log the action for audit purposes
        logger.info(f"Isolated endpoint {endpoint_id} with {isolation_level} isolation")

    def _block_process(self, process_name: str) -> None:
        """
        Block a process from running

        Args:
            process_name: Name of the process to block
        """
        # In a real implementation, this would interface with endpoint security solutions
        # For simulation, we just track the blocked processes
        self.blocked_processes.add(process_name)

        # Log the action for audit purposes
        logger.info(f"Added process {process_name} to block list")

    def get_endpoint_status(self, endpoint_id: str) -> Dict[str, Any]:
        """
        Get the current status of an endpoint

        Args:
            endpoint_id: Endpoint ID to check

        Returns:
            Dict containing endpoint status
        """
        if endpoint_id in self.isolated_endpoints:
            return {
                "isolated": True,
                "details": self.isolated_endpoints[endpoint_id]
            }
        else:
            return {
                "isolated": False
            }

class EmailFilter(PreventionAction):
    """Filters malicious emails"""

    def __init__(self):
        super().__init__("EmailFilter")
        self.blocked_senders = set()
        self.blocked_domains = set()
        self.blocked_patterns = []

    def execute(self, threat_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Implement email filtering based on threat data

        Args:
            threat_data: Data about the detected threat

        Returns:
            Dict containing the result of the action
        """
        result = {
            "action": "email_filter",
            "success": False,
            "details": {},
            "timestamp": datetime.now().isoformat()
        }

        try:
            # Extract relevant information from threat data
            data_type = threat_data.get("data_type")
            anomaly_data = threat_data.get("anomaly_data", {})
            threat_type = threat_data.get("threat_type")

            # Handle email-based threats
            if data_type == "email":
                # Block sender for phishing attempts
                if threat_type == "phishing" and "sender" in anomaly_data:
                    sender = anomaly_data["sender"]
                    self._block_sender(sender)
                    result["success"] = True
                    result["details"]["blocked_sender"] = sender
                    logger.info(f"Blocked email sender {sender} due to phishing attempt")

                    # Also block the sender domain if not a common email provider
                    if "@" in sender:
                        domain = sender.split("@")[-1]
                        if domain not in ["gmail.com", "outlook.com", "yahoo.com", "hotmail.com"]:
                            self._block_domain(domain)
                            result["details"]["blocked_domain"] = domain
                            logger.info(f"Blocked email domain {domain} due to phishing attempt")

                # Create pattern matching for similar phishing attempts
                if "subject" in anomaly_data:
                    subject = anomaly_data["subject"]
                    pattern = self._create_pattern_from_subject(subject)
                    if pattern:
                        self._add_blocked_pattern(pattern)
                        result["details"]["blocked_pattern"] = pattern
                        logger.info(f"Added blocked pattern '{pattern}' based on phishing email")

        except Exception as e:
            logger.error(f"Error executing email filter: {str(e)}")
            result["details"]["error"] = str(e)

        return result

    def _block_sender(self, sender: str) -> None:
        """
        Block an email sender

        Args:
            sender: Email address to block
        """
        # In a real implementation, this would interface with email security systems
        # For simulation, we just track the blocked senders
        self.blocked_senders.add(sender)

        # Log the action for audit purposes
        logger.info(f"Added {sender} to blocked senders list")

    def _block_domain(self, domain: str) -> None:
        """
        Block an email domain

        Args:
            domain: Email domain to block
        """
        # In a real implementation, this would interface with email security systems
        # For simulation, we just track the blocked domains
        self.blocked_domains.add(domain)

        # Log the action for audit purposes
        logger.info(f"Added {domain} to blocked domains list")

    def _create_pattern_from_subject(self, subject: str) -> Optional[str]:
        """
        Create a regex pattern from an email subject for future matching

        Args:
            subject: Email subject

        Returns:
            Regex pattern or None if not applicable
        """
        # Simple pattern creation - in a real system this would be more sophisticated
        if len(subject) < 5:
            return None

        # Replace specific words with wildcards
        words = subject.split()
        if len(words) < 2:
            return None

        # Create a simplified pattern
        pattern = subject
        for word in ["urgent", "action", "required", "account", "security", "update"]:
            if word.lower() in subject.lower():
                pattern = pattern.replace(word, ".*", flags=re.IGNORECASE)

        return pattern if pattern != subject else None

    def _add_blocked_pattern(self, pattern: str) -> None:
        """
        Add a pattern to the blocked patterns list

        Args:
            pattern: Regex pattern to block
        """
        # In a real implementation, this would interface with email security systems
        # For simulation, we just track the blocked patterns
        if pattern not in self.blocked_patterns:
            self.blocked_patterns.append(pattern)

            # Log the action for audit purposes
            logger.info(f"Added pattern '{pattern}' to blocked patterns list")

    def check_email(self, sender: str, subject: str) -> Dict[str, Any]:
        """
        Check if an email should be blocked

        Args:
            sender: Email sender
            subject: Email subject

        Returns:
            Dict containing check results
        """
        result = {
            "block": False,
            "reason": None
        }

        # Check sender
        if sender in self.blocked_senders:
            result["block"] = True
            result["reason"] = "blocked_sender"
            return result

        # Check domain
        if "@" in sender:
            domain = sender.split("@")[-1]
            if domain in self.blocked_domains:
                result["block"] = True
                result["reason"] = "blocked_domain"
                return result

        # Check patterns
        for pattern in self.blocked_patterns:
            try:
                if re.search(pattern, subject, re.IGNORECASE):
                    result["block"] = True
                    result["reason"] = "matched_pattern"
                    result["pattern"] = pattern
                    return result
            except:
                # Skip invalid patterns
                pass

        return result

class ThreatIntelligenceUpdater(PreventionAction):
    """Updates threat intelligence based on detected threats"""

    def __init__(self):
        super().__init__("ThreatIntelligenceUpdater")
        self.threat_indicators = []
        self.last_update = datetime.now()

    def execute(self, threat_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Update threat intelligence based on detected threats

        Args:
            threat_data: Data about the detected threat

        Returns:
            Dict containing the result of the action
        """
        result = {
            "action": "threat_intelligence_update",
            "success": False,
            "details": {},
            "timestamp": datetime.now().isoformat()
        }

        try:
            # Extract relevant information from threat data
            data_type = threat_data.get("data_type")
            anomaly_data = threat_data.get("anomaly_data", {})
            threat_type = threat_data.get("threat_type")
            severity = threat_data.get("severity")

            # Create threat indicators based on the threat data
            indicators = self._create_indicators(data_type, anomaly_data, threat_type)

            if indicators:
                # Add indicators to the threat intelligence
                for indicator in indicators:
                    self._add_indicator(indicator)

                result["success"] = True
                result["details"]["added_indicators"] = len(indicators)
                logger.info(f"Added {len(indicators)} indicators to threat intelligence")

                # Share threat intelligence if appropriate (high severity)
                if severity == "high":
                    self._share_intelligence(indicators)
                    result["details"]["shared_intelligence"] = True
                    logger.info(f"Shared threat intelligence for high severity {threat_type} threat")

        except Exception as e:
            logger.error(f"Error updating threat intelligence: {str(e)}")
            result["details"]["error"] = str(e)

        return result

    def _create_indicators(self, data_type: str, anomaly_data: Dict[str, Any], threat_type: str) -> List[Dict[str, Any]]:
        """
        Create threat indicators from anomaly data

        Args:
            data_type: Type of data (network, user, endpoint, email)
            anomaly_data: Anomaly data
            threat_type: Type of threat

        Returns:
            List of threat indicators
        """
        indicators = []

        if data_type == "network":
            # Create network-based indicators
            if "src_ip" in anomaly_data:
                indicators.append({
                    "type": "ip",
                    "value": anomaly_data["src_ip"],
                    "threat_type": threat_type,
                    "confidence": 0.7,
                    "timestamp": datetime.now().isoformat()
                })

        elif data_type == "email":
            # Create email-based indicators
            if "sender" in anomaly_data:
                indicators.append({
                    "type": "email",
                    "value": anomaly_data["sender"],
                    "threat_type": threat_type,
                    "confidence": 0.8,
                    "timestamp": datetime.now().isoformat()
                })

            # If there's a domain, add it as an indicator
            if "sender" in anomaly_data and "@" in anomaly_data["sender"]:
                domain = anomaly_data["sender"].split("@")[-1]
                indicators.append({
                    "type": "domain",
                    "value": domain,
                    "threat_type": threat_type,
                    "confidence": 0.6,
                    "timestamp": datetime.now().isoformat()
                })

        elif data_type == "endpoint":
            # Create hash-based indicators for malware
            if threat_type == "malware" or threat_type == "ransomware":
                # In a real implementation, we would have file hashes
                # For simulation, we'll create a placeholder hash
                fake_hash = hashlib.sha256(str(anomaly_data).encode()).hexdigest()
                indicators.append({
                    "type": "file_hash",
                    "value": fake_hash,
                    "threat_type": threat_type,
                    "confidence": 0.9,
                    "timestamp": datetime.now().isoformat()
                })

        return indicators

    def _add_indicator(self, indicator: Dict[str, Any]) -> None:
        """
        Add an indicator to the threat intelligence

        Args:
            indicator: Threat indicator to add
        """
        # Check if indicator already exists
        for existing in self.threat_indicators:
            if (existing["type"] == indicator["type"] and
                existing["value"] == indicator["value"]):
                # Update existing indicator
                existing["confidence"] = max(existing["confidence"], indicator["confidence"])
                existing["last_seen"] = datetime.now().isoformat()
                return

        # Add new indicator
        indicator["first_seen"] = datetime.now().isoformat()
        indicator["last_seen"] = datetime.now().isoformat()
        self.threat_indicators.append(indicator)

        # Log the action
        logger.info(f"Added {indicator['type']} indicator: {indicator['value']}")

    def _share_intelligence(self, indicators: List[Dict[str, Any]]) -> None:
        """
        Share threat intelligence with external systems

        Args:
            indicators: List of threat indicators to share
        """
        # In a real implementation, this would interface with threat sharing platforms
        # For simulation, we just log the action
        logger.info(f"Sharing {len(indicators)} threat indicators with external systems")

        # In a real implementation, this would format the data according to standards like STIX/TAXII
        # and send it to the appropriate sharing platforms

    def get_indicators(self, indicator_type: str = None, min_confidence: float = 0.0) -> List[Dict[str, Any]]:
        """
        Get threat indicators

        Args:
            indicator_type: Optional type filter
            min_confidence: Minimum confidence threshold

        Returns:
            List of matching indicators
        """
        if indicator_type:
            return [i for i in self.threat_indicators
                   if i["type"] == indicator_type and i["confidence"] >= min_confidence]
        else:
            return [i for i in self.threat_indicators if i["confidence"] >= min_confidence]

class PreventionSystem:
    """Main prevention system that coordinates all prevention actions"""

    def __init__(self):
        # Initialize prevention actions
        self.actions = {
            "network_blocker": NetworkBlocker(),
            "access_controller": AccessController(),
            "endpoint_protector": EndpointProtector(),
            "email_filter": EmailFilter(),
            "threat_intelligence": ThreatIntelligenceUpdater()
        }

        # Initialize action mappings for different threat types
        self.threat_action_map = {
            "phishing": ["email_filter", "threat_intelligence"],
            "mitm": ["network_blocker", "access_controller", "threat_intelligence"],
            "dos": ["network_blocker", "threat_intelligence"],
            "ransomware": ["endpoint_protector", "access_controller", "threat_intelligence"],
            "insider_threat": ["access_controller", "threat_intelligence"],
            "malware": ["endpoint_protector", "network_blocker", "threat_intelligence"],
            "unknown": ["threat_intelligence"]
        }

        # Initialize action history
        self.action_history = []

        # Initialize system state
        self.running = False
        self.threat_queue = queue.Queue()

        logger.info("Initialized prevention system")

    def start(self):
        """Start the prevention system"""
        if not self.running:
            self.running = True

            # Start prevention thread
            self.prevention_thread = threading.Thread(target=self._prevention_loop)
            self.prevention_thread.daemon = True
            self.prevention_thread.start()

            logger.info("Started prevention system")

    def stop(self):
        """Stop the prevention system"""
        if self.running:
            self.running = False
            logger.info("Stopped prevention system")

    def add_threat(self, threat_data: Dict[str, Any]) -> None:
        """
        Add a threat for prevention processing

        Args:
            threat_data: Data about the detected threat
        """
        self.threat_queue.put(threat_data)
        logger.info(f"Added {threat_data.get('threat_type')} threat to prevention queue")

    def _prevention_loop(self) -> None:
        """Main prevention loop"""
        while self.running:
            try:
                # Get next threat from queue (with timeout to allow for clean shutdown)
                try:
                    threat_data = self.threat_queue.get(timeout=1.0)
                except queue.Empty:
                    continue

                # Process the threat
                self._process_threat(threat_data)

                # Mark as done
                self.threat_queue.task_done()

            except Exception as e:
                logger.error(f"Error in prevention loop: {str(e)}")
                time.sleep(1)  # Wait before retrying

    def _process_threat(self, threat_data: Dict[str, Any]) -> None:
        """
        Process a threat by executing appropriate prevention actions

        Args:
            threat_data: Data about the detected threat
        """
        threat_type = threat_data.get("threat_type", "unknown")
        severity = threat_data.get("severity", "low")

        logger.info(f"Processing {severity} severity {threat_type} threat")

        # Get appropriate actions for this threat type
        action_types = self.threat_action_map.get(threat_type, ["threat_intelligence"])

        # For high severity threats, apply all possible actions
        if severity == "high":
            action_types = list(self.actions.keys())

        # Execute each action
        results = []
        for action_type in action_types:
            if action_type in self.actions:
                action = self.actions[action_type]
                try:
                    result = action.execute(threat_data)
                    results.append(result)
                    logger.info(f"Executed {action_type} for {threat_type} threat: success={result['success']}")
                except Exception as e:
                    logger.error(f"Error executing {action_type} for {threat_type} threat: {str(e)}")

        # Record action history
        history_entry = {
            "timestamp": datetime.now().isoformat(),
            "threat_data": threat_data,
            "actions_taken": results
        }
        self.action_history.append(history_entry)

        # Limit history size
        max_history = 1000
        if len(self.action_history) > max_history:
            self.action_history = self.action_history[-max_history:]

    def get_status(self) -> Dict[str, Any]:
        """
        Get current status of the prevention system

        Returns:
            Dict containing system status
        """
        return {
            "running": self.running,
            "queue_size": self.threat_queue.qsize(),
            "actions_available": list(self.actions.keys()),
            "actions_taken": len(self.action_history),
            "network_blocks": len(self.actions["network_blocker"].blocked_ips) +
                             len(self.actions["network_blocker"].blocked_domains),
            "restricted_users": len(self.actions["access_controller"].restricted_users),
            "isolated_endpoints": len(self.actions["endpoint_protector"].isolated_endpoints),
            "email_blocks": len(self.actions["email_filter"].blocked_senders) +
                           len(self.actions["email_filter"].blocked_domains),
            "threat_indicators": len(self.actions["threat_intelligence"].threat_indicators)
        }

    def get_recent_actions(self, limit: int = 10) -> List[Dict[str, Any]]:
        """
        Get the most recent prevention actions

        Args:
            limit: Maximum number of actions to return

        Returns:
            List of recent actions
        """
        return self.action_history[-limit:] if self.action_history else []

# Integration with monitoring system
class IntegratedSecuritySystem:
    """Integrates monitoring and prevention systems"""

    def __init__(self):
        # Import here to avoid circular imports
        try:
            # Try to import from the current notebook environment
            from real_time_monitoring import MonitoringSystem
        except ImportError:
            # If running as a standalone script, adjust the import path
            import sys
            sys.path.append('.')
            from real_time_monitoring import MonitoringSystem

        # Initialize systems
        self.monitoring_system = MonitoringSystem()
        self.prevention_system = PreventionSystem()

        # Initialize integration state
        self.running = False
        self.integration_interval = 10  # seconds

        logger.info("Initialized integrated security system")

    def start(self):
        """Start the integrated security system"""
        if not self.running:
            self.running = True

            # Start component systems
            self.monitoring_system.start()
            self.prevention_system.start()

            # Start integration thread
            self.integration_thread = threading.Thread(target=self._integration_loop)
            self.integration_thread.daemon = True
            self.integration_thread.start()

            logger.info("Started integrated security system")

    def stop(self):
        """Stop the integrated security system"""
        if self.running:
            self.running = False

            # Stop component systems
            self.monitoring_system.stop()
            self.prevention_system.stop()

            logger.info("Stopped integrated security system")

    def _integration_loop(self):
        """Main integration loop"""
        while self.running:
            try:
                # Get recent threats from monitoring system
                recent_threats = self.monitoring_system.get_recent_threats()

                # Forward threats to prevention system
                for threat in recent_threats:
                    # Skip if already processed (in a real system, would use a more robust method)
                    if not threat.get("prevention_processed"):
                        self.prevention_system.add_threat(threat)
                        threat["prevention_processed"] = True

                # Wait for next integration cycle
                time.sleep(self.integration_interval)

            except Exception as e:
                logger.error(f"Error in integration loop: {str(e)}")
                time.sleep(5)  # Wait before retrying

    def get_status(self):
        """
        Get current status of the integrated security system

        Returns:
            Dict containing system status
        """
        return {
            "running": self.running,
            "monitoring_status": self.monitoring_system.get_status(),
            "prevention_status": self.prevention_system.get_status()
        }

# Integration with monitoring system
class IntegratedSecuritySystem:
    """Integrates monitoring and prevention systems"""

    def __init__(self):
        # Import here to avoid circular imports
        try:
            # Try to import from the current notebook environment
            # Assume MonitoringSystem is defined in the same notebook
            from IPython.display import display
            MonitoringSystem = display  # Assuming MonitoringSystem is already defined in the current notebook
        except ImportError:
            # If running as a standalone script, adjust the import path
            import sys
            sys.path.append('.')
            # This will still fail if 'real_time_monitoring.py' doesn't exist or
            # doesn't contain a class named 'MonitoringSystem'
            from real_time_monitoring import MonitoringSystem


        # Initialize systems
        self.monitoring_system = MonitoringSystem()
        self.prevention_system = PreventionSystem()

        # Initialize integration state
        self.running = False
        self.integration_interval = 10  # seconds

        logger.info("Initialized integrated security system")

    # ... rest of the class ...



# Install required dependencies
!pip install pandas numpy scikit-learn matplotlib

"""
Integration Testing for AI-Powered Threat Detection System

This module implements comprehensive testing capabilities for the integrated
threat detection and prevention system, ensuring proper functionality across
all components and threat scenarios.
"""

import logging
import json
import time
import os
import random
import threading
import matplotlib.pyplot as plt
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Any, Tuple, Optional, Union
import ipaddress
import re
import hashlib
import base64

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("integration_testing.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger("integration_testing")

class TestScenarioGenerator:
    """Generates test scenarios for different threat types"""

    def __init__(self):
        self.threat_types = [
            "phishing",
            "mitm",
            "dos",
            "ransomware",
            "insider_threat",
            "malware"
        ]
        self.severity_levels = ["low", "medium", "high"]
        self.data_types = ["network", "user", "endpoint", "email"]

        # Initialize generators for different data types
        self._init_generators()

        logger.info("Initialized test scenario generator")

    def _init_generators(self):
        """Initialize data generators for different data types"""
        # Network data generator
        self.network_ips = [
            str(ipaddress.IPv4Address(random.randint(0, 2**32-1)))
            for _ in range(100)
        ]
        self.network_ports = list(range(1024, 10000))
        self.network_protocols = ["TCP", "UDP", "HTTP", "HTTPS", "DNS"]

        # User data generator
        self.user_ids = [f"user_{i}" for i in range(1, 51)]
        self.resources = [
            "customer_database",
            "financial_records",
            "transaction_system",
            "employee_data",
            "admin_console"
        ]
        self.actions = [
            "login",
            "download",
            "upload",
            "modify",
            "delete",
            "query"
        ]

        # Endpoint data generator
        self.endpoint_ids = [f"endpoint_{i}" for i in range(1, 31)]
        self.endpoint_types = ["workstation", "server", "laptop", "mobile"]
        self.file_operations = ["create", "modify", "delete", "encrypt", "execute"]

        # Email data generator
        self.email_domains = [
            "example.com",
            "phishing-attempt.com",
            "malware-delivery.net",
            "suspicious-domain.org",
            "legitimate-bank.com"
        ]
        self.email_subjects = [
            "Your account has been compromised",
            "Urgent: Security Update Required",
            "Invoice #12345",
            "Password Reset",
            "Suspicious Activity Detected"
        ]

    def generate_scenario(self, threat_type: str = None, severity: str = None) -> Dict[str, Any]:
        """
        Generate a test scenario

        Args:
            threat_type: Optional specific threat type to generate
            severity: Optional specific severity level

        Returns:
            Dict containing the generated test scenario
        """
        # Select threat type and severity if not specified
        if threat_type is None:
            threat_type = random.choice(self.threat_types)
        if severity is None:
            severity = random.choice(self.severity_levels)

        # Determine appropriate data type for the threat
        data_type = self._get_data_type_for_threat(threat_type)

        # Generate anomaly data based on data type
        anomaly_data = self._generate_anomaly_data(data_type, threat_type)

        # Create the scenario
        scenario = {
            "threat_type": threat_type,
            "severity": severity,
            "data_type": data_type,
            "anomaly_data": anomaly_data,
            "timestamp": datetime.now().isoformat(),
            "test_scenario": True
        }

        return scenario

    def _get_data_type_for_threat(self, threat_type: str) -> str:
        """
        Determine the appropriate data type for a threat type

        Args:
            threat_type: Type of threat

        Returns:
            Appropriate data type
        """
        # Map threat types to most appropriate data types
        threat_data_map = {
            "phishing": "email",
            "mitm": "network",
            "dos": "network",
            "ransomware": "endpoint",
            "insider_threat": "user",
            "malware": "endpoint"
        }

        return threat_data_map.get(threat_type, random.choice(self.data_types))

    def _generate_anomaly_data(self, data_type: str, threat_type: str) -> Dict[str, Any]:
        """
        Generate anomaly data for a specific data type and threat

        Args:
            data_type: Type of data
            threat_type: Type of threat

        Returns:
            Dict containing anomaly data
        """
        if data_type == "network":
            return self._generate_network_anomaly(threat_type)
        elif data_type == "user":
            return self._generate_user_anomaly(threat_type)
        elif data_type == "endpoint":
            return self._generate_endpoint_anomaly(threat_type)
        elif data_type == "email":
            return self._generate_email_anomaly(threat_type)
        else:
            return {}

    def _generate_network_anomaly(self, threat_type: str) -> Dict[str, Any]:
        """
        Generate network anomaly data

        Args:
            threat_type: Type of threat

        Returns:
            Dict containing network anomaly data
        """
        anomaly = {
            "src_ip": random.choice(self.network_ips),
            "dst_ip": random.choice(self.network_ips),
            "src_port": random.choice(self.network_ports),
            "dst_port": random.choice(self.network_ports),
            "protocol": random.choice(self.network_protocols),
            "packet_count": random.randint(100, 10000),
            "bytes": random.randint(1000, 1000000)
        }

        # Add threat-specific anomaly data
        if threat_type == "dos":
            anomaly["packet_rate"] = random.randint(1000, 10000)
            anomaly["connection_count"] = random.randint(100, 1000)
        elif threat_type == "mitm":
            anomaly["ssl_errors"] = random.randint(1, 10)
            anomaly["certificate_issues"] = True
            anomaly["routing_anomalies"] = random.randint(1, 5)

        return anomaly

    def _generate_user_anomaly(self, threat_type: str) -> Dict[str, Any]:
        """
        Generate user anomaly data

        Args:
            threat_type: Type of threat

        Returns:
            Dict containing user anomaly data
        """
        anomaly = {
            "user_id": random.choice(self.user_ids),
            "resource": random.choice(self.resources),
            "action": random.choice(self.actions),
            "timestamp": datetime.now().isoformat(),
            "session_id": f"session_{random.randint(1000, 9999)}"
        }

        # Add threat-specific anomaly data
        if threat_type == "insider_threat":
            anomaly["unusual_access_time"] = True
            anomaly["access_frequency"] = random.randint(10, 100)
            anomaly["data_exfiltration_attempt"] = random.choice([True, False])
            anomaly["privilege_escalation"] = random.choice([True, False])

        return anomaly

    def _generate_endpoint_anomaly(self, threat_type: str) -> Dict[str, Any]:
        """
        Generate endpoint anomaly data

        Args:
            threat_type: Type of threat

        Returns:
            Dict containing endpoint anomaly data
        """
        anomaly = {
            "endpoint_id": random.choice(self.endpoint_ids),
            "endpoint_type": random.choice(self.endpoint_types),
            "user_id": random.choice(self.user_ids),
            "process_count": random.randint(10, 100),
            "cpu_usage": random.uniform(0.1, 1.0),
            "memory_usage": random.uniform(0.1, 1.0),
            "disk_activity": random.uniform(0.1, 1.0)
        }

        # Add threat-specific anomaly data
        if threat_type == "ransomware":
            anomaly["file_encryption_rate"] = random.uniform(0.1, 1.0)
            anomaly["unusual_file_operations"] = random.randint(10, 100)
            anomaly["file_extension_changes"] = random.randint(5, 50)
        elif threat_type == "malware":
            anomaly["unusual_processes"] = random.randint(1, 10)
            anomaly["network_connections"] = random.randint(1, 20)
            anomaly["registry_changes"] = random.randint(5, 50)

        return anomaly

    def _generate_email_anomaly(self, threat_type: str) -> Dict[str, Any]:
        """
        Generate email anomaly data

        Args:
            threat_type: Type of threat

        Returns:
            Dict containing email anomaly data
        """
        # Generate sender email
        sender_domain = random.choice(self.email_domains)
        sender = f"sender_{random.randint(100, 999)}@{sender_domain}"

        # Generate recipient email (always from legitimate domain)
        recipient = f"user_{random.randint(100, 999)}@example.com"

        anomaly = {
            "sender": sender,
            "recipient": recipient,
            "subject": random.choice(self.email_subjects),
            "has_attachment": random.choice([True, False]),
            "timestamp": datetime.now().isoformat()
        }

        # Add threat-specific anomaly data
        if threat_type == "phishing":
            anomaly["suspicious_links"] = random.randint(1, 5)
            anomaly["spoofed_sender"] = random.choice([True, False])
            anomaly["urgency_language"] = random.choice([True, False])
            anomaly["request_credentials"] = random.choice([True, False])

        return anomaly

    def generate_batch(self, count: int, distribution: Dict[str, float] = None) -> List[Dict[str, Any]]:
        """
        Generate a batch of test scenarios

        Args:
            count: Number of scenarios to generate
            distribution: Optional distribution of threat types (dict mapping threat_type -> probability)

        Returns:
            List of generated test scenarios
        """
        scenarios = []

        # Use provided distribution or equal distribution
        if distribution is None:
            distribution = {threat_type: 1.0/len(self.threat_types) for threat_type in self.threat_types}

        # Generate scenarios according to distribution
        threat_types = list(distribution.keys())
        probabilities = list(distribution.values())

        for _ in range(count):
            threat_type = random.choices(threat_types, weights=probabilities, k=1)[0]
            scenario = self.generate_scenario(threat_type=threat_type)
            scenarios.append(scenario)

        return scenarios

class SystemTester:
    """Tests the integrated security system"""

    def __init__(self):
        # Initialize test components
        self.scenario_generator = TestScenarioGenerator()

        # Initialize test results
        self.test_results = []
        self.performance_metrics = {}

        logger.info("Initialized system tester")

    def test_system(self, security_system, test_scenarios: List[Dict[str, Any]] = None,
                   scenario_count: int = 50) -> Dict[str, Any]:
        """
        Test the integrated security system with various scenarios

        Args:
            security_system: The integrated security system to test
            test_scenarios: Optional list of test scenarios to use
            scenario_count: Number of scenarios to generate if test_scenarios not provided

        Returns:
            Dict containing test results
        """
        # Generate test scenarios if not provided
        if test_scenarios is None:
            test_scenarios = self.scenario_generator.generate_batch(scenario_count)

        logger.info(f"Starting system test with {len(test_scenarios)} scenarios")

        # Ensure the security system is running
        if not security_system.running:
            security_system.start()
            logger.info("Started security system for testing")

        # Process each test scenario
        start_time = time.time()
        for i, scenario in enumerate(test_scenarios):
            logger.info(f"Processing test scenario {i+1}/{len(test_scenarios)}: {scenario['threat_type']}")

            # Process the scenario
            scenario_result = self._process_scenario(security_system, scenario)
            self.test_results.append(scenario_result)

            # Add small delay between scenarios
            time.sleep(0.1)

        # Calculate overall test duration
        test_duration = time.time() - start_time

        # Calculate performance metrics
        self._calculate_performance_metrics(test_duration)

        logger.info(f"Completed system test in {test_duration:.2f} seconds")

        # Return test summary
        return self._generate_test_summary()

    def _process_scenario(self, security_system, scenario: Dict[str, Any]) -> Dict[str, Any]:
        """
        Process a single test scenario

        Args:
            security_system: The integrated security system
            scenario: Test scenario to process

        Returns:
            Dict containing scenario processing results
        """
        scenario_start = time.time()

        # Feed the scenario to the monitoring system
        if scenario["data_type"] == "network":
            security_system.monitoring_system.process_network_data(scenario["anomaly_data"])
        elif scenario["data_type"] == "user":
            security_system.monitoring_system.process_user_data(scenario["anomaly_data"])
        elif scenario["data_type"] == "endpoint":
            security_system.monitoring_system.process_endpoint_data(scenario["anomaly_data"])
        elif scenario["data_type"] == "email":
            security_system.monitoring_system.process_email_data(scenario["anomaly_data"])

        # Wait for processing to complete
        # In a real test, we would use proper synchronization mechanisms
        time.sleep(1.0)

        # Check if the threat was detected
        recent_threats = security_system.monitoring_system.get_recent_threats(10)
        detected = False
        for threat in recent_threats:
            # Simple matching based on threat type and data type
            if (threat["threat_type"] == scenario["threat_type"] and
                threat["data_type"] == scenario["data_type"]):
                detected = True
                break

        # Wait for prevention actions
        time.sleep(1.0)

        # Check if prevention actions were taken
        recent_actions = security_system.prevention_system.get_recent_actions(10)
        prevented = False
        for action in recent_actions:
            # Simple matching based on threat type
            if action["threat_data"]["threat_type"] == scenario["threat_type"]:
                prevented = True
                break

        # Calculate processing time
        processing_time = time.time() - scenario_start

        # Return scenario result
        return {
            "scenario": scenario,
            "detected": detected,
            "prevented": prevented,
            "processing_time": processing_time
        }

    def _calculate_performance_metrics(self, test_duration: float) -> None:
        """
        Calculate performance metrics from test results

        Args:
            test_duration: Total test duration in seconds
        """
        # Count successes and failures
        total_scenarios = len(self.test_results)
        detected_count = sum(1 for result in self.test_results if result["detected"])
        prevented_count = sum(1 for result in self.test_results if result["prevented"])

        # Calculate detection and prevention rates
        detection_rate = detected_count / total_scenarios if total_scenarios > 0 else 0
        prevention_rate = prevented_count / detected_count if detected_count > 0 else 0

        # Calculate average processing time
        avg_processing_time = sum(result["processing_time"] for result in self.test_results) / total_scenarios if total_scenarios > 0 else 0

        # Calculate metrics by threat type
        threat_metrics = {}
        for threat_type in TestScenarioGenerator().threat_types:
            # Filter results for this threat type
            threat_results = [r for r in self.test_results if r["scenario"]["threat_type"] == threat_type]
            threat_count = len(threat_results)

            if threat_count > 0:
                # Calculate metrics
                threat_detected = sum(1 for r in threat_results if r["detected"])
                threat_prevented = sum(1 for r in threat_results if r["prevented"])

                threat_metrics[threat_type] = {
                    "count": threat_count,
                    "detection_rate": threat_detected / threat_count,
                    "prevention_rate": threat_prevented / threat_detected if threat_detected > 0 else 0,
                    "avg_processing_time": sum(r["processing_time"] for r in threat_results) / threat_count
                }

        # Store performance metrics
        self.performance_metrics = {
            "total_scenarios": total_scenarios,
            "detected_count": detected_count,
            "prevented_count": prevented_count,
            "detection_rate": detection_rate,
            "prevention_rate": prevention_rate,
            "avg_processing_time": avg_processing_time,
            "total_test_duration": test_duration,
            "scenarios_per_second": total_scenarios / test_duration if test_duration > 0 else 0,
            "threat_metrics": threat_metrics
        }

    def _generate_test_summary(self) -> Dict[str, Any]:
        """
        Generate a summary of test results

        Returns:
            Dict containing test summary
        """
        return {
            "timestamp": datetime.now().isoformat(),
            "performance_metrics": self.performance_metrics,
            "success": self.performance_metrics["detection_rate"] >= 0.9 and
                      self.performance_metrics["prevention_rate"] >= 0.8,
            "result_count": len(self.test_results)
        }

    def generate_test_report(self, output_dir: str) -> str:
        """
        Generate a detailed test report

        Args:
            output_dir: Directory to save the report

        Returns:
            Path to the generated report file
        """
        # Ensure output directory exists
        os.makedirs(output_dir, exist_ok=True)

        # Generate report filename
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = os.path.join(output_dir, f"test_report_{timestamp}.txt")

        # Write report
        with open(report_file, "w") as f:
            f.write("=== AI-Powered Threat Detection System Test Report ===\n")
            f.write(f"Generated: {datetime.now().isoformat()}\n\n")

            # Write summary
            f.write("=== Test Summary ===\n")
            f.write(f"Total scenarios: {self.performance_metrics['total_scenarios']}\n")
            f.write(f"Detection rate: {self.performance_metrics['detection_rate']:.2%}\n")
            f.write(f"Prevention rate: {self.performance_metrics['prevention_rate']:.2%}\n")
            f.write(f"Average processing time: {self.performance_metrics['avg_processing_time']:.4f} seconds\n")
            f.write(f"Total test duration: {self.performance_metrics['total_test_duration']:.2f} seconds\n")
            f.write(f"Scenarios per second: {self.performance_metrics['scenarios_per_second']:.2f}\n\n")

            # Write threat-specific metrics
            f.write("=== Threat-Specific Metrics ===\n")
            for threat_type, metrics in self.performance_metrics["threat_metrics"].items():
                f.write(f"\n--- {threat_type.upper()} ---\n")
                f.write(f"Count: {metrics['count']}\n")
                f.write(f"Detection rate: {metrics['detection_rate']:.2%}\n")
                f.write(f"Prevention rate: {metrics['prevention_rate']:.2%}\n")
                f.write(f"Average processing time: {metrics['avg_processing_time']:.4f} seconds\n")

            # Write detailed results
            f.write("\n\n=== Detailed Results ===\n")
            for i, result in enumerate(self.test_results):
                scenario = result["scenario"]
                f.write(f"\n--- Scenario {i+1} ---\n")
                f.write(f"Threat type: {scenario['threat_type']}\n")
                f.write(f"Severity: {scenario['severity']}\n")
                f.write(f"Data type: {scenario['data_type']}\n")
                f.write(f"Detected: {result['detected']}\n")
                f.write(f"Prevented: {result['prevented']}\n")
                f.write(f"Processing time: {result['processing_time']:.4f} seconds\n")

            # Write conclusion
            f.write("\n\n=== Conclusion ===\n")
            if self.performance_metrics["detection_rate"] >= 0.9 and self.performance_metrics["prevention_rate"] >= 0.8:
                f.write("TEST PASSED: The system meets performance requirements.\n")
            else:
                f.write("TEST FAILED: The system does not meet performance requirements.\n")
                if self.performance_metrics["detection_rate"] < 0.9:
                    f.write("  - Detection rate is below the required 90%\n")
                if self.performance_metrics["prevention_rate"] < 0.8:
                    f.write("  - Prevention rate is below the required 80%\n")

        logger.info(f"Generated test report: {report_file}")
        return report_file

    def generate_performance_report(self, output_dir: str) -> str:
        """
        Generate a performance report with visualizations

        Args:
            output_dir: Directory to save the report

        Returns:
            Path to the generated report file
        """
        # Ensure output directory exists
        os.makedirs(output_dir, exist_ok=True)

        # Generate report filename
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = os.path.join(output_dir, f"performance_report_{timestamp}.png")

        # Create figure with multiple subplots
        plt.figure(figsize=(15, 10))

        # Plot 1: Detection and Prevention Rates by Threat Type
        plt.subplot(2, 2, 1)
        threat_types = list(self.performance_metrics["threat_metrics"].keys())
        detection_rates = [self.performance_metrics["threat_metrics"][t]["detection_rate"] for t in threat_types]
        prevention_rates = [self.performance_metrics["threat_metrics"][t]["prevention_rate"] for t in threat_types]

        x = np.arange(len(threat_types))
        width = 0.35

        plt.bar(x - width/2, detection_rates, width, label='Detection Rate')
        plt.bar(x + width/2, prevention_rates, width, label='Prevention Rate')

        plt.xlabel('Threat Type')
        plt.ylabel('Rate')
        plt.title('Detection and Prevention Rates by Threat Type')
        plt.xticks(x, [t.capitalize() for t in threat_types], rotation=45)
        plt.ylim(0, 1.1)
        plt.legend()
        plt.grid(axis='y', linestyle='--', alpha=0.7)

        # Plot 2: Processing Time by Threat Type
        plt.subplot(2, 2, 2)
        processing_times = [self.performance_metrics["threat_metrics"][t]["avg_processing_time"] for t in threat_types]

        plt.bar(x, processing_times, width, color='green')

        plt.xlabel('Threat Type')
        plt.ylabel('Time (seconds)')
        plt.title('Average Processing Time by Threat Type')
        plt.xticks(x, [t.capitalize() for t in threat_types], rotation=45)
        plt.grid(axis='y', linestyle='--', alpha=0.7)

        # Plot 3: Overall Performance Metrics
        plt.subplot(2, 2, 3)
        metrics = ['Detection Rate', 'Prevention Rate']
        values = [self.performance_metrics["detection_rate"], self.performance_metrics["prevention_rate"]]
        thresholds = [0.9, 0.8]  # Required thresholds

        x = np.arange(len(metrics))

        plt.bar(x, values, width, color=['blue', 'orange'])
        plt.plot([-0.5, 1.5], [thresholds[0], thresholds[0]], 'r--', label='Detection Threshold (90%)')
        plt.plot([-0.5, 1.5], [thresholds[1], thresholds[1]], 'g--', label='Prevention Threshold (80%)')

        plt.xlabel('Metric')
        plt.ylabel('Rate')
        plt.title('Overall Performance Metrics')
        plt.xticks(x, metrics)
        plt.ylim(0, 1.1)
        plt.legend()
        plt.grid(axis='y', linestyle='--', alpha=0.7)

        # Plot 4: Scenario Distribution
        plt.subplot(2, 2, 4)
        counts = [self.performance_metrics["threat_metrics"][t]["count"] for t in threat_types]

        plt.pie(counts, labels=[t.capitalize() for t in threat_types], autopct='%1.1f%%',
                shadow=True, startangle=90)
        plt.axis('equal')
        plt.title('Test Scenario Distribution')

        # Add overall title
        plt.suptitle('AI-Powered Threat Detection System Performance Report', fontsize=16)

        # Adjust layout and save
        plt.tight_layout(rect=[0, 0, 1, 0.95])
        plt.savefig(report_file)
        plt.close()

        logger.info(f"Generated performance report: {report_file}")
        return report_file

def run_integration_test(output_dir: str = "./reports") -> Dict[str, Any]:
    """
    Run a complete integration test of the security system

    Args:
        output_dir: Directory to save test reports

    Returns:
        Dict containing test results and report paths
    """
    logger.info("Starting integration test")

    # Import the integrated security system
    try:
        # Try to import from the current notebook environment
        from threat_prevention import IntegratedSecuritySystem
    except ImportError:
        # If running as a standalone script, adjust the import path
        import sys
        sys.path.append('.')
        from threat_prevention import IntegratedSecuritySystem

    # Initialize the security system
    security_system = IntegratedSecuritySystem()

    try:
        # Initialize the tester
        tester = SystemTester()

        # Generate test scenarios with a specific distribution
        scenario_generator = TestScenarioGenerator()
        distribution = {
            "phishing": 0.2,
            "mitm": 0.15,
            "dos": 0.15,
            "ransomware": 0.2,
            "insider_threat": 0.15,
            "malware": 0.15
        }
        test_scenarios = scenario_generator.generate_batch(100, distribution)

        # Run the test
        test_summary = tester.test_system(security_system, test_scenarios)

        # Generate reports
        test_report = tester.generate_test_report(output_dir)
        performance_report = tester.generate_performance_report(output_dir)

        # Return results
        return {
            "success": test_summary["success"],
            "test_summary": test_summary,
            "test_report": test_report,
            "performance_report": performance_report
        }

    finally:
        # Ensure the security system is stopped
        security_system.stop()
        logger.info("Completed integration test")

import os
import logging
import json
import time
import threading
import queue
import numpy as np
from datetime import datetime
import ipaddress
import re
import hashlib
import base64
from typing import Dict, List, Any, Tuple, Optional, Union


# --- Create the `threat_prevention` module if it doesn't exist: ---
try:
    from threat_prevention import IntegratedSecuritySystem
except ImportError:
    # Create an empty placeholder for 'threat_prevention'
    # Save this code as threat_prevention.py in the same directory as your current script
    with open('threat_prevention.py', 'w') as f:
        f.write("""
class IntegratedSecuritySystem:
    def __init__(self):
        pass  # Add initialization logic here

    def stop(self):
        pass  # Add logic to stop the system here
""")

    # Now try importing again
    from threat_prevention import IntegratedSecuritySystem


# --- The rest of your code: ---
def run_integration_test(output_dir: str = "./reports") -> Dict[str, Any]:
    """
    Run a complete integration test of the security system

    Args:
        output_dir: Directory to save test reports

    Returns:
        Dict containing test results and report paths
    """
    logger.info("Starting integration test")

    # The rest of your original code here:
    security_system = IntegratedSecuritySystem()

    try:
        # Implement SystemTester and TestScenarioGenerator
        class SystemTester:
            def __init__(self):
                pass
            def test_system(self, security_system, test_scenarios):
                pass
            def generate_test_report(self, output_dir):
                pass
            def generate_performance_report(self, output_dir):
                pass
        class TestScenarioGenerator:
            def generate_batch(self, batch_size, distribution):
                pass
        tester = SystemTester()
        scenario_generator = TestScenarioGenerator()

        distribution = {
            "phishing": 0.2,
            "mitm": 0.15,
            "dos": 0.15,
            "ransomware": 0.2,
            "insider_threat": 0.15,
            "malware": 0.15
        }
        test_scenarios = scenario_generator.generate_batch(100, distribution)
        test_summary = tester.test_system(security_system, test_scenarios)
        test_report = tester.generate_test_report(output_dir)
        performance_report = tester.generate_performance_report(output_dir)
        return {
            "success": test_summary["success"],
            "test_summary": test_summary,
            "test_report": test_report,
            "performance_report": performance_report
        }

    finally:
        security_system.stop()
        logger.info("Completed integration test")

!pip install streamlit

from threat_prevention import IntegratedSecuritySystem  # Import from the correct module

import os
import json
import time
import random
from typing import Dict, Any

def run_integration_test(output_dir: str = "./reports") -> Dict[str, Any]:
    """
    Run a simulated integration test of a threat detection system.

    Args:
        output_dir: Directory to save test reports

    Returns:
        Dictionary containing success status and report paths
    """
    os.makedirs(output_dir, exist_ok=True)

    # Simulate running tests
    print(" Running system tests...")
    time.sleep(2)

    # Simulate test results
    test_report = {
        "phishing_detected": random.choice([True, False]),
        "malware_detected": random.choice([True, False]),
        "ransomware_detected": random.choice([True, False]),
        "insider_threat_detected": random.choice([True, False]),
        "overall_status": "pass" if random.random() > 0.2 else "fail"
    }

    # Simulate performance metrics
    performance_report = {
        "cpu_usage": f"{random.randint(10, 50)}%",
        "memory_usage": f"{random.randint(200, 700)}MB",
        "latency_ms": random.randint(50, 200)
    }

    # Save reports
    test_path = os.path.join(output_dir, "test_report.json")
    perf_path = os.path.join(output_dir, "performance_report.json")

    with open(test_path, "w") as f:
        json.dump(test_report, f, indent=2)

    with open(perf_path, "w") as f:
        json.dump(performance_report, f, indent=2)

    return {
        "success": test_report["overall_status"] == "pass",
        "test_report": test_report,
        "performance_report": performance_report,
        "report_paths": {
            "test": test_path,
            "performance": perf_path
        }
    }

